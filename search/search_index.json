{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tapestry","text":"<p>Tapestry is a framework for writing and maintaining (postgres)SQL queries and (pgTAP) tests using Jinja templates.</p> <p>Tapestry is written in Rust but it can be used with applications written in any programming language. It's purely a command line tool that renders Jinja templates into SQL files. How to load the resulting SQL code into memory and use it at runtime is entirely up to the application.</p> <p>This approach of loading SQL from files is not new, in fact there are existing libraries such as yesql, hugsql (Clojure), aiosql (Python) etc. that provide excellent abstractions for it. In absence of such a lib for the language of your choice, it shouldn't take more than a few lines of code to implement a simple file loader. In Rust apps, I simply use the <code>include_str!</code> macro.</p> <p>One limitation is that tapestry can be used with PostgreSQL only, because of the tight coupling with pgTAP.</p> <p>To understand the motivation behind this tool, please check the Rationale.</p>"},{"location":"rationale/","title":"Rationale","text":""},{"location":"rationale/#problems-with-using-raw-sql-in-application-code","title":"Problems with using raw SQL in application code","text":"<p>For many years, I've believed that,</p> <ol> <li> <p>it's a good idea to write raw SQL queries (safely) for interacting    with an RDBMS from application code using libs such as yesql,    aiosql etc.</p> </li> <li> <p>it's ok to add reasonable amount of business logic in the SQL    queries, rather than using SQL merely for data access.</p> </li> </ol> <p>Still, I've had concerns about using these ideas in practice, specially in serious projects.</p>"},{"location":"rationale/#unit-testing-sql-queries","title":"Unit testing SQL queries","text":"<p>Typically, unit tests are written against application code. As more and more business logic gets moved out of the application and into SQL queries, the queries become longer and more complex. In contrast, the application code is reduced to just making db calls using the driver/client library. At this point, it makes more sense to test the queries than the application code.</p> <p>Fortunately for PostgreSQL, we have the excellent PgTAP extension that makes it easy to write unit tests for raw queries. Just like the raw queries themselves, pgTap tests are typically defined in SQL files. But since the query and the tests are in separate files, it's possible that one modifies the SQL query, but forgets to update the tests, and the tests could still pass!</p> <p>How to ensure that the tests actually run the exact same query that's being run by the application?</p>"},{"location":"rationale/#maintenance-overhead-of-multiple-slightly-differing-queries","title":"Maintenance overhead of multiple, slightly differing queries","text":"<p>An application often needs to issue similar queries but returning different set of columns or with different <code>WHERE</code> clauses based on user input. In such cases, a unique query needs to be written and maintained for every combination of the input parameters.  This could result in multiple queries that differ only slightly. If some core part of the query needs a change, one needs to remember to update multiple SQL files.</p> <p>Moreover, higher level abstractions (e.g. yesql etc.) usually cache queries in memory, so they require the queries to be given a name or an identifier. Since the queries differ only slightly, trying to give them unique names can be tricky. </p>"},{"location":"rationale/#how-tapestry-solves-it","title":"How tapestry solves it?","text":"<p>Tapestry was built to specifically address the above problems and concerns. It does so by generating actual queries as well as pgTAP test files from Jinja templates, instead of having the user write raw SQL.</p>"},{"location":"rationale/#query-templates","title":"Query templates","text":"<ul> <li>You write query templates instead of raw queries</li> <li>Multiple queries can be mapped to the same query template. Mapping   is defined in the <code>tapestry.toml</code> manifest file.</li> <li>User defined Jinja variables can be used for conditionally adding or   omitting parts of the query e.g. a <code>WHERE</code> condition or column to   return. These Jinja vars are also defined in the manifest file.</li> <li>Thus, it's easy to generate and maintain multiple queries that are   similar enough to be defined using a single query template.</li> </ul>"},{"location":"rationale/#test-templates","title":"Test templates","text":"<ul> <li>pgTAP tests are also written as Jinja templates</li> <li>Test templates are mapped to queries, again in the manifest   file. One query can be mapped to multiple test templates.</li> <li>When tapestry renders the final test file from a test template, a   special Jinja variable <code>{{ prepared_statement }}</code> gets expanded to   the actual query that the test template is mapped to.</li> <li>This way, the generated test SQL file is guaranteed to have the   exact same query which is used by the application code.</li> </ul>"},{"location":"rationale/#naming-conventions","title":"Naming conventions","text":"<p>Tapestry suggests some conventions for naming queries consistently but they are not mandatory. More about query and test naming conventions in the user guide.</p>"},{"location":"user-guide/","title":"Overview","text":"<p>Tapestry is built to address the peculiar concerns that I've had about using libraries such as yesql, aiosql and the likes. While I agree with the philosophy behind such libs\u2014that SQL code is better written as SQL directly rather than building it through ORMs, query builders or worse, by string interpolation or concatenation\u2014I've had some concerns about using the approach in practice.</p> <p>To understand more about the problems and how tapestry addresses them, please check the Rationale page.</p> <p>The general idea behind this tool is, instead of users writing raw SQL queries, have them write Jinja templates from which SQL queries as well as pgTAP tests can be generated.</p> <p>Here is a high level overview of how you'd use tapestry in your project:</p> <ol> <li> <p>Create a directory inside your project where the templates will be    located. The <code>tapestry init</code> command does this for you.</p> </li> <li> <p>Add some information in the <code>tapestry.toml</code> manifest file:</p> <ol> <li>Lists of query templates, queries and test templates along with     the mappings between them</li> <li>Location of query templates and test templates (input files)</li> <li>Location of where the output files are to be created</li> <li>etc...</li> </ol> </li> <li> <p>Run <code>tapestry render</code> command to generate the SQL files, both for    queries as well as tests.</p> </li> <li> <p>Use a lib such as yesql, aiosql etc. to load the queries rendered    by the previous step into the application runtime.</p> </li> <li> <p>Use <code>pg_prove</code> to run the pgTAP tests, preferably as part of    CD/CI. You'd need to implement some kind of automation for    this. The github repo also includes a docker image that may help    with this.</p> </li> </ol>"},{"location":"user-guide/commands/","title":"Commands","text":"<p>The <code>tapestry</code> CLI provides the following commands:</p>"},{"location":"user-guide/commands/#init","title":"init","text":"<p>The <code>init</code> command can be used for scaffolding a new <code>tapestry</code> \"project\". It will create the directory structure and also write a bare minimum manifest file for us. In a real project, you'd run this command from within the main project directory, so that the files can be committed to the same repo. Example:</p> <p>Running the following command,</p> <pre><code>tapestry init myproj\n</code></pre> <p>.. will create the following directory structure</p> <pre><code>$ cd myproj\n$ tree -a --charset=ascii .\n.\n|-- .pg_format\n|   `-- config\n|-- tapestry.toml\n`-- templates\n    |-- queries\n    `-- tests\n</code></pre>"},{"location":"user-guide/commands/#validate","title":"validate","text":"<p>The <code>validate</code> command checks and ensures that the manifest file is valid. Additionally it also verifies that the paths referenced in the manifest actually exist and are readable.</p>"},{"location":"user-guide/commands/#render","title":"render","text":"<p>The <code>render</code> command renders all the template files into SQL files.</p>"},{"location":"user-guide/commands/#summary","title":"summary","text":"<p>The <code>summary</code> command prints a tabular summary of all queries along with their associated (query) templates and tests.</p>"},{"location":"user-guide/docker/","title":"Docker","text":""},{"location":"user-guide/docker/#docker-based-workflow-for-running-pgtap-tests","title":"Docker based workflow for running pgTAP tests","text":"<p><code>tapestry</code> only generates SQL files for queries and <code>pgTAP</code> tests. To be able to run the tests you need to install and setup:</p> <ol> <li>PostgreSQL server</li> <li><code>pgTAP</code>, which is a postgres extension</li> <li><code>pg_prove</code>, which is a command line test runner/harness for <code>pgTAP</code>    tests</li> </ol> <p>While these can be setup manually, the <code>tapestry</code> github repo provides a docker based workflow for easily running tests generated by <code>tapestry</code> against a temporary pg database.</p> <p>The relevant files can be found inside the <code>docker</code> directory under project root.</p> <p>Note</p> <p>I use podman instead of docker for managing containers. Hence all the docker commands in this doc have been actually tested using podman only. As podman claims CLI compatibility with docker, I am assuming that replacing <code>podman</code> with <code>docker</code> in the below mentioned commands should just work. If that's not the case, please create an issue on github.</p>"},{"location":"user-guide/docker/#build-the-docker-image","title":"Build the docker image","text":"<pre><code>cd docker\npodman build -t tapestry-testbed -f ./Dockerfile\n</code></pre>"},{"location":"user-guide/docker/#start-container-for-postgres-process","title":"Start container for postgres process","text":"<pre><code>podman run --name taptestbed \\\n    --env POSTGRES_PASSWORD=secret \\\n    -d \\\n    -p 5432:5432 \\\n    tapestry-testbed:latest\n</code></pre> <p>Verify that the <code>5432</code> port is reachable from the host machine.</p> <pre><code>nc -vz localhost 5432\n</code></pre> <p>The above <code>podman run</code> command will create a container and start it. After that you can manage the container using the <code>podman container</code> commands</p> <pre><code>podman container stop taptestbed\npodman container start taptestbed\n</code></pre>"},{"location":"user-guide/docker/#running-tests","title":"Running tests","text":"<p>The <code>pg_prove</code> executable is part of the image that we have built. But to be able to run tests inside the container, we need to make the database schema and the test SQL files accessible to it. For this we bind mount a volume into the container when running it, using the <code>--volume</code> option.</p> <p>The container image has a bash script <code>run-tests</code> installed into it which picks up the schema and the test SQL files from the mounted dir.</p> <p>The <code>run-tests</code> scripts makes certain assumptions about organization of files inside the mounted dir. Inside the container, the dir must be mounted at <code>/tmp/tapestry-data/</code> and there must be be two sub directories under it:</p> <ol> <li> <p><code>schema</code>: All SQL files inside this dir will be executed against    the database server in lexicographical order to setup a temporary    test database.</p> </li> <li> <p><code>tests</code>: All SQL files inside this dir will be considered as tests    and specified as arguments to the <code>pg_prove</code> command.</p> </li> </ol> <p>Once such a local directory is created, you can run the tests as follows,</p> <pre><code>podman run -it \\\n    --rm \\\n    --network podman \\\n    -v ~/tapestry-data/:/tmp/tapestry-data/ \\\n    --env PGPASSWORD=secret \\\n    --env PGHOST=$(podman container inspect -f '{{.NetworkSettings.IPAddress}}' taptestbed) \\\n    tapestry-testbed:latest \\\n    run-tests -c -d temptestdb\n</code></pre> <p>In the above command, <code>temptestdb</code> is the name of the db that will be created by the <code>run-tests</code> script. If your schema files themselves take care of creating the db, then you can specify that as the name and omit the <code>-c</code> flag.</p> <p>To know more about the usage of <code>run-tests</code> script, run,</p> <pre><code>podman run -it --rm tapestry-testbed:latest run-tests --help\n</code></pre>"},{"location":"user-guide/getting-started/","title":"Getting started","text":"<p>This tutorial is to help you get started with tapestry. It's assumed that the following software is installed on your system:</p> <ul> <li><code>tapestry</code></li> <li><code>pg_format</code></li> <li>a working installation of PostgreSQL (official   docs)</li> <li><code>pgTAP</code> and <code>pg_prove</code></li> </ul>"},{"location":"user-guide/getting-started/#sample-database","title":"Sample database","text":"<p>For this tutorial, we'll use the chinook sample database. Download and import it as follows,</p> <pre><code>wget -P /tmp/ https://github.com/lerocha/chinook-database/releases/download/v1.4.5/Chinook_PostgreSql_SerialPKs.sql\ncreatedb chinook\npsql -d chinook -f /tmp/Chinook_PostgreSql_SerialPKs.sql\n</code></pre>"},{"location":"user-guide/getting-started/#init","title":"Init","text":"<p>We'll start by running the <code>tapestry init</code> command, which will create the directory structure and also write a bare minimum manifest file for us. In a real project, you'd run this command from within the main project directory, so that the files can be committed to the same repo. But for this tutorial, you can run it from any suitable location e.g. the home dir <code>~/</code></p> <pre><code>cd ~/\ntapestry init chinook\n</code></pre> <p>This will create a directory named <code>chinook</code> with following structure,</p> <pre><code>$ cd chinook\n$ tree -a --charset=ascii .\n.\n|-- .pg_format\n|   `-- config\n|-- tapestry.toml\n`-- templates\n    |-- queries\n    `-- tests\n</code></pre> <p>Let's look at the <code>tapestry.toml</code> manifest file that has been created (I've stripped out some comments for conciseness)</p> <pre><code>$ cat tapestry.toml\nplaceholder = \"posargs\"\n\nquery_templates_dir = \"templates/queries\"\ntest_templates_dir = \"templates/tests\"\n\nqueries_output_dir = \"output/queries\"\ntests_output_dir = \"output/tests\"\n\n[formatter.pgFormatter]\nexec_path = \"pg_format\"\nconf_path = \"./.pg_format/config\"\n\n# [[query_templates]]\n\n# [[queries]]\n\n# [[test_templates]]\n</code></pre> <p><code>placeholder</code> defines the style of generated queries. Default is <code>posargs</code> (positional arguments) which will generate queries with <code>$1</code>, <code>$2</code> etc as the placeholders. These are suitable for defining prepared statements.</p> <p>Then there are four toml keys for defining directories,</p> <ol> <li> <p><code>query_templates_dir</code> is where the query templates will be located</p> </li> <li> <p><code>test_templates_dir</code> is where the test templates will be located</p> </li> <li> <p><code>queries_output_dir</code> is where the SQL files for queries will be    generated</p> </li> <li> <p><code>tests_output_dir</code> is where the SQL files for pgTAP tests will be    generated.</p> </li> </ol> <p>All directory paths are relative to the manifest file.</p> <p>You may have noticed that the <code>init</code> command created only the templates dirs. <code>output</code> dirs will be created when <code>tapestry render</code> is called for the first time.</p> <p>The <code>init</code> command has also created a <code>pg_format</code> config file for us. This is because it found the <code>pg_format</code> executable on <code>PATH</code>. Refer to the <code>pg_format</code> section for more details.</p>"},{"location":"user-guide/getting-started/#adding-a-query_template-to-generate-queries","title":"Adding a query_template to generate queries","text":"<p>Now we'll define a query template. But before that, you might want to get yourself familiar with the chinook database's schema.</p> <p>Suppose we have an imaginary application built on top of the chinook database in which the following queries need to be run,</p> <ol> <li> <p>list all artists with their longest songs</p> </li> <li> <p>list top 10 artists having longest songs</p> </li> <li> <p>list top 5 artists having longest songs, and of a specific genre</p> </li> </ol> <p>As you can see, we'd need different queries for each of the 3 requirements, but all have a common logic of finding longest songs per artist. Using Jinja syntax, we can write a query template that covers all 3 cases as follows,</p> <pre><code>SELECT\n    ar.artist_id,\n    ar.name,\n    max(milliseconds) * interval '1 ms' AS duration\nFROM\n    track t\n    INNER JOIN album al USING (album_id)\n    INNER JOIN artist ar USING (artist_id)\n{% if cond__genre %}\n    INNER JOIN genre g USING (genre_id)\n  WHERE\n  g.name = {{ placeholder('genre') }}\n{% endif %}\nGROUP BY\n    ar.artist_id\nORDER BY\n-- Descending order because we want the top artists\n    duration DESC\n{% if cond__limit %}\n  LIMIT {{ placeholder('limit') }}\n{% endif %}\n;\n</code></pre> <p>We've used some custom Jinja variables for selectively including parts of SQL in the query. These need to be prefixed with <code>cond__</code> and have to be defined in the manifest file (we'll come to that a bit later).</p> <p>We have also used the custom Jinja function <code>placeholder</code> which takes one arg and expands to a placeholder in the actual query. This will be clear once we render the queries.</p> <p>Let's save the above query template to the file <code>templates/queries/artists_long_songs.sql.j2</code>.</p> <p>And now we'll proceed to defining the query_template and the queries that it can generate in the manifest file. Edit the <code>tapestry.toml</code> file by appending the following lines to it.</p> <pre><code>[[query_templates]]\npath = \"artists_long_songs.sql.j2\"\nall_conds = [ \"genre\", \"limit\" ]\n</code></pre> <p>To define a <code>query_template</code> we need to specify 2 keys:</p> <ol> <li> <p><code>path</code> i.e. where the template file is located relative to the    <code>query_templates_dir</code> defined earlier in the manifest. <code>path</code>    itself is considered as the unique identifier for the query    template.</p> </li> <li> <p><code>all_conds</code> is a set of values that will be converted to <code>cond__</code>    Jinja variables. In this case it means there are two <code>cond__</code> Jinja    templates supported by the template - <code>cond__genre</code> and    <code>cond__limit</code>. Note that they are defined in the manifest without    the <code>cond__</code> suffix.</p> </li> </ol> <p>We can now define three different queries that map to the same query_template</p> <pre><code>[[queries]]\nid = \"artists_long_songs\"\ntemplate = \"artists_long_songs.sql.j2\"\nconds = []\n\n[[queries]]\nid = \"artists_long_songs*limit\"\ntemplate = \"artists_long_songs.sql.j2\"\nconds = [ \"limit\" ]\n\n[[queries]]\nid = \"artists_long_songs@genre*limit\"\ntemplate = \"artists_long_songs.sql.j2\"\nconds = [ \"genre\", \"limit\" ]\n</code></pre> <p>To define a query, we need to specify 3 keys,</p> <ol> <li> <p><code>id</code> is an identifier for the query. Notice that we're following a    naming convention by using special chars <code>@</code> and <code>*</code>. Read more    about Query naming conventions.</p> </li> <li> <p><code>template</code> is reference to the query template that we defined    earlier.</p> </li> <li> <p><code>conds</code> is a subset of the <code>all_conds</code> key that's defined for the    linked query template. In the context of this query, only the    corresponding <code>cond__</code> Jinja variables will have the value <code>true</code>,    and the rest of them will be <code>false</code>.</p> </li> </ol> <p>We've defined three queries that use the same template. In the first query, both the <code>conds</code> that the template supports i.e. \"genre\" and \"limit\" are false. In the second query, \"limit\" is true but \"genre\" is false. In the third query, both \"genre\" and \"limit\" are true. Queries will be rendered based on these variables and the <code>{% if cond__.. %}</code> expressions in the template.</p> <p>Don't worry if all this doesn't make much sense at this point. Things will be clear when we'll run <code>tapestry render</code> shortly.</p>"},{"location":"user-guide/getting-started/#rendering","title":"Rendering","text":"<p>Now let's run the <code>tapestry render</code> command.</p> <pre><code>tapestry render\n</code></pre> <p>And you'll notice some files created in our directory.</p> <pre><code>$ tree -a --charset=ascii .\n.\n|-- .pg_format\n|   `-- config\n|-- output\n|   |-- queries\n|   |   |-- artists_long_songs-genre-limit.sql\n|   |   |-- artists_long_songs-limit.sql\n|   |   `-- artists_long_songs.sql\n|   `-- tests\n|-- tapestry.toml\n`-- templates\n    |-- queries\n    |   `-- artists_long_songs.sql.j2\n    `-- tests\n</code></pre> <p>Here is what the generated output files look like:</p> artists_long_songs.sqlartists_long_songs-limit.sqlartists_long_songs-genre-limit.sql <pre><code>SELECT\n    ar.artist_id,\n    ar.name,\n    max(milliseconds) * interval '1 ms' AS duration\nFROM\n    track t\n    INNER JOIN album al USING (album_id)\n    INNER JOIN artist ar USING (artist_id)\nGROUP BY\n    ar.artist_id\nORDER BY\n    -- Descending order because we want the top artists\n    duration DESC;\n</code></pre> <pre><code>SELECT\n    ar.artist_id,\n    ar.name,\n    max(milliseconds) * interval '1 ms' AS duration\nFROM\n    track t\n    INNER JOIN album al USING (album_id)\n    INNER JOIN artist ar USING (artist_id)\nGROUP BY\n    ar.artist_id\nORDER BY\n    -- Descending order because we want the top artists\n    duration DESC\nLIMIT $1;\n</code></pre> <pre><code>SELECT\n    ar.artist_id,\n    ar.name,\n    max(milliseconds) * interval '1 ms' AS duration\nFROM\n    track t\n    INNER JOIN album al USING (album_id)\n    INNER JOIN artist ar USING (artist_id)\n    INNER JOIN genre g USING (genre_id)\nWHERE\n    g.name = $1\nGROUP BY\n    ar.artist_id\nORDER BY\n    -- Descending order because we want the top artists\n    duration DESC\nLIMIT $2;\n</code></pre> <p>As you can see, the output SQL is formatted by <code>pg_format</code>.</p>"},{"location":"user-guide/getting-started/#adding-a-test_template","title":"Adding a test_template","text":"<p>Now that we've defined and rendered queries, let's add <code>test_template</code>. Again there are two changes required - an entry in the manifest file and the Jinja template itself.</p> <p>Add the following lines to the manifest file.</p> <pre><code>[[test_templates]]\nquery = \"artists_long_songs@genre*limit\"\npath = \"artists_long_songs-genre-limit_test.sql.j2\"\n</code></pre> <p>Here we're referencing the query <code>artists_long_songs@genre*limit</code> hence this test is meant for that query. The <code>path</code> key points to a test template file that we need to create. So let's create the file <code>templates/tests/artists_long_songs-genre-limit_test.sql.j2</code> with the following contents:</p> <pre><code>PREPARE artists_long_songs(varchar, int) AS\n{{ prepared_statement }};\n\nBEGIN;\nSELECT\n    plan (1);\n\n-- start(noformat)\n-- Run the tests.\nSELECT results_eq(\n    'EXECUTE artists_long_songs(''Rock'', 10)',\n    $$VALUES\n        (22, 'Led Zeppelin'::varchar, '00:26:52.329'::interval),\n        (58, 'Deep Purple'::varchar, '00:19:56.094'::interval),\n        (59, 'Santana'::varchar, '00:17:50.027'::interval),\n        (136, 'Terry Bozzio, Tony Levin &amp; Steve Stevens'::varchar, '00:14:40.64'::interval),\n        (140, 'The Doors'::varchar, '00:11:41.831'::interval),\n        (90, 'Iron Maiden'::varchar, '00:11:18.008'::interval),\n        (23, 'Frank Zappa &amp; Captain Beefheart'::varchar, '00:11:17.694'::interval),\n        (128, 'Rush'::varchar, '00:11:07.428'::interval),\n        (76, 'Creedence Clearwater Revival'::varchar, '00:11:04.894'::interval),\n        (92, 'Jamiroquai'::varchar, '00:10:16.829'::interval)\n    $$,\n    'Verify return value'\n);\n-- Finish the tests and clean up.\n-- end(noformat)\n\nSELECT\n    *\nFROM\n    finish ();\nROLLBACK;\n</code></pre> <p>The test syntax is SQL only but with some additional functions installed by <code>pgTAP</code>. If you are not familiar with <code>pgTAP</code> you can go through it's documentation. But for this tutorial, it's sufficient to understand that the <code>{{ prepared_statement }}</code> Jinja variable is made available to this template, and when it's rendered it will expand to the actual query.</p> <p>Let's run the <code>render</code> command again.</p> <pre><code>tapestry render\n</code></pre> <p>And now you should see the pgTAP test file created at <code>output/tests/artists_long_songs-genre-limit_test.sql</code>.</p> <p>Note</p> <p>Here the file stem of the test template <code>path</code> itself was used as the output file name. But it's also possible to explicitly specify it in the manifest file (see output in <code>test_templates</code> docs).</p> <p>This is how the rendered test file looks like,</p> <pre><code>PREPARE artists_long_songs (varchar, int) AS\nSELECT\n    ar.artist_id,\n    ar.name,\n    max(milliseconds) * interval '1 ms' AS duration\nFROM\n    track t\n    INNER JOIN album al USING (album_id)\n    INNER JOIN artist ar USING (artist_id)\n    INNER JOIN genre g USING (genre_id)\nWHERE\n    g.name = $1\nGROUP BY\n    ar.artist_id\nORDER BY\n    -- Descending order because we want the top artists\n    duration DESC\nLIMIT $2;\n\nBEGIN;\nSELECT\n    plan (1);\n-- start(noformat)\n-- Run the tests.\nSELECT results_eq(\n    'EXECUTE artists_long_songs(''Rock'', 10)',\n    $$VALUES\n        (22, 'Led Zeppelin'::varchar, '00:26:52.329'::interval),\n        (58, 'Deep Purple'::varchar, '00:19:56.094'::interval),\n        (59, 'Santana'::varchar, '00:17:50.027'::interval),\n        (136, 'Terry Bozzio, Tony Levin &amp; Steve Stevens'::varchar, '00:14:40.64'::interval),\n        (140, 'The Doors'::varchar, '00:11:41.831'::interval),\n        (90, 'Iron Maiden'::varchar, '00:11:18.008'::interval),\n        (23, 'Frank Zappa &amp; Captain Beefheart'::varchar, '00:11:17.694'::interval),\n        (128, 'Rush'::varchar, '00:11:07.428'::interval),\n        (76, 'Creedence Clearwater Revival'::varchar, '00:11:04.894'::interval),\n        (92, 'Jamiroquai'::varchar, '00:10:16.829'::interval)\n    $$,\n    'Verify return value'\n);\n-- Finish the tests and clean up.\n-- end(noformat)\nSELECT\n    *\nFROM\n    finish ();\nROLLBACK;\n</code></pre>"},{"location":"user-guide/getting-started/#run-tests","title":"Run tests","text":"<p>Assuming that all the above mentioned prerequisites are installed, you can run the tests as follows,</p> <pre><code>sudo -u postgres pg_prove -d chinook --verbose output/tests/*.sql\n</code></pre> <p>If all goes well, the tests should pass and you should see output similar to,</p> <pre><code>1..1\nok 1 - Verify return value\nok\nAll tests successful.\nFiles=1, Tests=1,  0 wallclock secs ( 0.03 usr  0.01 sys +  0.01 cusr  0.00 csys =  0.05 CPU)\nResult: PASS\n</code></pre>"},{"location":"user-guide/getting-started/#thats-all","title":"That's all!","text":"<p>If you've reached this far, you should now have a basic understanding of what <code>tapestry</code> is and how to use it. Next, it'd be a good idea to understand the manifest file in more detail.</p> <p>Note</p> <p>The chinook example discussed in this tutorial can also be found in the github repo under the <code>examples/chinook</code> directory (there are a few more tests included for reference).</p>"},{"location":"user-guide/install/","title":"Installation","text":"<p>Until tapestry is published to crates.io, you can install it directly from github,</p> <pre><code>    cargo install --git https://github.com/naiquevin/tapestry.git\n</code></pre>"},{"location":"user-guide/install/#additional-dependencies","title":"Additional dependencies","text":"<p>Tapestry depends on pg_format for formatting the generated SQL files. It's not a hard requirement but recommended.</p> <p>On MacOS, it can be installed using homebrew,</p> <pre><code>    brew install pgformatter\n</code></pre> <p>Note that you need to install <code>pg_format</code> on the machine where you'd be rendering the SQL files using <code>tapestry</code> e.g. on your workstation and/or the build server.</p>"},{"location":"user-guide/install/#dependencies-for-running-tests","title":"Dependencies for running tests","text":"<p>If you are using tapestry to render tests (which you should, because that's what the tool is meant for!) then you'd also need the <code>pgTAP</code> extension and the <code>pg_prove</code> command line tool.</p> <p><code>pgTAP</code> can be easily built from source. Refer to the instructions here.</p> <p>You can install <code>pg_prove</code> from a CPAN distribution as follows:</p> <pre><code>sudo cpan TAP::Parser::SourceHandler::pgTAP\n</code></pre> <p>Refer to the pgTAP installation guide for more details.</p> <p>As <code>tapestry</code> is a postgres specific tool, it goes without saying that you'd need a working installation of postgres to be able to run the tests. Please refer to the official documentation for that.</p>"},{"location":"user-guide/manifest/","title":"Manifest","text":"<p>Every <code>tapestry</code> \"project\" has a <code>tapestry.toml</code> file which is called the manifest. It is in TOML format and serves the dual purpose of configuration as well as a registry of the following entities:</p> <ol> <li><code>query_templates</code></li> <li><code>queries</code></li> <li><code>test_templates</code></li> </ol> <p>The various sections or top level <code>TOML</code> keys are described in detail below. When going through this doc, you may find it helpful to refer to the chinook example in the github repo. If you haven't checked the Getting started section, it's recommended to read it first.</p>"},{"location":"user-guide/manifest/#placeholder","title":"placeholder","text":"<p>The <code>placeholder</code> key is for configuring the style of the placeholder syntax for parameters i.e. the values values that are substituted into the statement when it is executed.</p> <p>Two options are supported:</p>"},{"location":"user-guide/manifest/#posargs","title":"posargs","text":"<p><code>posargs</code> is short for positional arguments. The placeholders refer to the parameters by positions e.g. <code>$1</code>, <code>$2</code> etc. This is the same syntax that's used for defining prepared statements or SQL functions in postgres.</p> <p>This option is suitable when your db driver or SQL library accepts queries in prepared statements syntax. E.g. sqlx (Rust).</p> <p>Default: The manifest file auto-generated upon running the <code>tapestry init</code> command will have,</p> <pre><code>placeholder = posargs\n</code></pre>"},{"location":"user-guide/manifest/#variables","title":"variables","text":"<p>When <code>placeholder=variables</code> placeholders are added in the rendered query using the variable substitution syntax of postgres. The variable name in the query is preceded with colon e.g. <code>:email</code>, <code>:department</code></p> <p>This option is suitable when your db driver or SQL library accepts queries with variables. E.g. yesql, hugsql (Clojure), aiosql (Python)</p> <p>Examples</p> Templateplaceholder = posargsplaceholder = variables <pre><code>SELECT\n    *\nFROM\n    employees\nWHERE\n    email = {{ placeholder('email') }}\n    AND department = {{ placeholder('department') }};\n</code></pre> <pre><code>SELECT\n    *\nFROM\n    employees\nWHERE\n    email = $1\n    AND department = $2;\n</code></pre> <pre><code>SELECT\n    *\nFROM\n    employees\nWHERE\n    email = :email\n    AND department = :department;\n</code></pre> <p>Note</p> <p>Note that the <code>prepared_statement</code> Jinja variable available in test templates will always have <code>posargs</code> based placeholders even if the <code>placeholder</code> config in manifest file is set to <code>variables</code>. That's the reason the Jinja var is named <code>prepared_statement</code>.</p>"},{"location":"user-guide/manifest/#query_templates_dir","title":"query_templates_dir","text":"<p>Path where the query templates are located. The path is always relative to the manifest file.</p> <p>Default: The manifest file auto-generated upon running the <code>tapestry init</code> command will have,</p> <pre><code>query_templates_dir = \"templates/queries\"\n</code></pre>"},{"location":"user-guide/manifest/#test_templates_dir","title":"test_templates_dir","text":"<p>Path where the query templates are located. The path is always relative to the manifest file.</p> <p>Default: The manifest file auto-generated upon running the <code>tapestry init</code> command will have,</p> <pre><code>test_templates_dir = \"templates/tests\"\n</code></pre>"},{"location":"user-guide/manifest/#queries_output_dir","title":"queries_output_dir","text":"<p>Path to the output dir for the rendered queries. This path also needs to be defined relative to the manifest file.</p> <p>Default: The manifest file auto-generated upon running the <code>tapestry init</code> command will have,</p> <pre><code>queries_output_dir = \"output/queries\"\n</code></pre> <p>A common use case to modify this config would be to store SQL files in a directory outside of the tapestry \"project\" dir, so that only the SQL files in that directory can be packaged into the build artifact. There's no need to include the query/test template and the <code>pgTAP</code> test files in the build artifact. E.g.</p> <pre><code>queries_output_dir = \"../sql_queries\"\n</code></pre>"},{"location":"user-guide/manifest/#tests_output_dir","title":"tests_output_dir","text":"<p>Path to the output dir for rendered <code>pgTAP</code> tests. The path is always relative to the manifest file.</p> <p>Default: The manifest file auto-generated upon running the <code>tapestry init</code> command will have,</p> <pre><code>tests_output_dir = \"output/tests\"\n</code></pre>"},{"location":"user-guide/manifest/#formatterpgformatter","title":"formatter.pgFormatter","text":"<p>This section is for configuring the <code>pg_format</code> tool that <code>tapestry</code> uses for formatting the rendered SQL files.</p> <p>There two config params under this section:</p>"},{"location":"user-guide/manifest/#exec_path","title":"exec_path","text":"<p>Location of the <code>pg_format</code> executable.</p>"},{"location":"user-guide/manifest/#conf_path","title":"conf_path","text":"<p>Path to the <code>pg_format</code> config file. It can be used for configuring the behavior of <code>pg_format</code> when it gets executed on rendered SQL. As with all paths that we've seen so far, this one is also relative to the manifest file.</p> <p>Example</p> <pre><code>[formatter.pgFormatter]\nexec_path = \"pg_format\"\nconf_path = \"./.pg_format/config\"\n</code></pre> <p>As mentioned in the installation guide, <code>pg_format</code> is not a mandatory requirement but it's recommended.</p> <p>Upon running the <code>tapestry init</code> command, this section will be included in the auto-generated manifest file only if the executable <code>pg_format</code> is found on <code>PATH</code>. In that case, a default <code>pg_format</code> config file will also be created.</p> <p>To read more about configuring <code>pg_format</code> in the context of <code>tapestry</code>, refer to the pg_format section of the docs.</p>"},{"location":"user-guide/manifest/#query_templates","title":"query_templates","text":"<p><code>query_templates</code> is an array of tables in <code>TOML</code> parlance. So it needs to defined with double square brackets and can be specified multiple times in the manifest file.</p> <p>For every query template, there are two keys to be defined:</p>"},{"location":"user-guide/manifest/#path","title":"path","text":"<p>It's where the Jinja template file is located relative to the <code>query_templates_dir</code> defined earlier in the manifest. <code>path</code> itself is considered as the unique identifier for the query template.</p> <p>Use <code>.j2</code> extension as the convention for the query template file.</p>"},{"location":"user-guide/manifest/#all_conds","title":"all_conds","text":"<p>It's a set of values that will be converted to <code>cond__</code> Jinja variables that can be referenced inside the template. Note that they are defined in the manifest without the <code>cond__</code> suffix.</p> <p>For documentation on how to write a <code>query_template</code>, refer to Writing query templates</p> <p>Example: </p> <pre><code>[[query_templates]]\npath = \"artists_long_songs.sql.j2\"\nall_conds = [ \"genre\", \"limit\" ]\n\n[[query_templates]]\npath = \"songs_formats.sql.j2\"\nall_conds = [ \"artist\", \"file_format\", \"album_name\" ]\n</code></pre>"},{"location":"user-guide/manifest/#queries","title":"queries","text":"<p><code>queries</code> is an array of tables in <code>TOML</code> parlance. So it needs to defined with double square brackets and can be specified multiple times in the manifest file.</p> <p>A query can be defined using the following keys,</p>"},{"location":"user-guide/manifest/#id","title":"id","text":"<p><code>id</code> is an identifier for the query.</p>"},{"location":"user-guide/manifest/#template","title":"template","text":"<p><code>template</code> is a reference to a <code>query_template</code> defined previously in the manifest.</p>"},{"location":"user-guide/manifest/#conds","title":"conds","text":"<p><code>conds</code> is a subset of the <code>all_conds</code> key that's defined for the linked query template.</p>"},{"location":"user-guide/manifest/#output","title":"output","text":"<p><code>output</code> is the path to the output file where the SQL query will be rendered. It must be relative to the <code>queries_output_dir</code> config.</p> <p>It's optional to specify the <code>output</code>. If not specified, the filename of the output file will be derived by slugifying the <code>id</code>. This property allows us to use certain Naming conventions for giving suitable and consistent names to the queries.</p> <p>Example:</p> <pre><code>[[queries]]\nid = \"artists_long_songs@genre*limit\"\ntemplate = \"artists_long_songs.sql.j2\"\nconds = [ \"genre\", \"limit\" ]\n</code></pre>"},{"location":"user-guide/manifest/#test_templates","title":"test_templates","text":"<p><code>test_templates</code> is an array of tables in <code>TOML</code> parlance. So it needs to defined with double square brackets and can be specified multiple times in the manifest file.</p> <p>A <code>test_template</code> can be defined using the following keys,</p>"},{"location":"user-guide/manifest/#query","title":"query","text":"<p><code>query</code> is a reference to <code>query</code> defined in the manifest.</p>"},{"location":"user-guide/manifest/#path_1","title":"path","text":"<p><code>path</code> is the path to the jinja template for the <code>pgTAP</code> test. It must be relative to the <code>test_templates_dir</code>.</p> <p>Use <code>.j2</code> extension as the convention for the test template file.</p>"},{"location":"user-guide/manifest/#output_1","title":"output","text":"<p><code>output</code> is the path where the <code>pgTAP</code> test file will be rendered. It must be relative to the <code>tests_output_dir</code>. </p> <p>Specifying <code>output</code> for <code>test_templates</code> is optional. If not specified, it will be derived from the file stem of <code>path</code> i.e. by removing the <code>.j2</code> extension.</p> <p>For detailed documentation on how to write a <code>test_template</code>, refer to Writing test templates</p>"},{"location":"user-guide/naming-conventions/","title":"Query naming conventions","text":"<p>One of the problems that I have encountered when using SQL loading libraries such as yesql and aiosql is that the queries defined in SQL files need to be given unique names. Often, one ends up writing a group of queries that are mostly similar to each other and differ only slightly. Giving unique and consistent names to each query can become tricky.</p> <p>A tool like <code>tapestry</code> cannot automatically give a name to a query. However, since the queries are listed in the manifest file, we can partly address the problem with the use of naming conventions.</p> <p>These naming conventions involve clever use of special characters such as <code>@</code>, <code>+</code>, <code>&amp;</code> and <code>*</code>. Let's look at some examples from examples/chinook dir.</p> <pre><code>[[queries]]\nid = \"artists_long_songs@genre*limit\"\ntemplate = \"artists_long_songs.sql.j2\"\nconds = [ \"genre\", \"limit\" ]\n\n[[queries]]\nid = \"songs_formats@artist&amp;file_format+album\"\ntemplate = \"songs_formats.sql.j2\"\nconds = [ \"artist\", \"album_name\", \"file_format\" ]\n</code></pre> <p>In the above queries, the <code>id</code> is defined using an alphanumeric prefix (<code>artists_long_songs</code> and <code>songs_formats</code>) followed by suffix that's an encoding of the conditional Jinja variables relevant to the query.</p> <p>The convention is as follows,</p> <ul> <li><code>@</code> precedes \"cond\" vars used for conditionally including a filter   i.e. a <code>WHERE</code> clause.</li> </ul> <ul> <li><code>+</code> precedes \"cond\" vars used for conditionally returning a column</li> </ul> <ul> <li><code>*</code> precedes \"cond\" vars used for conditionally including any other   part of the query e.g. <code>LIMIT</code>, <code>ORDER BY</code> etc.</li> </ul> <ul> <li><code>&amp;</code> is used as a delimiter between two \"cond\" vars of same type   e.g. <code>@artist&amp;file_format</code>.</li> </ul> <p>The name of the <code>output</code> file for the SQL query will be generated by slugifying the id i.e. by replacing the above special characters with hyphen (<code>-</code>). In case of the above two queries, the output file names will be <code>artists_long_songs-genre-limit.sql</code> and <code>songs_formats-artist-file_format-album.sql</code> respectively.</p> <p>Note that these naming conventions are only recommended by <code>tapestry</code> and are not mandatory.</p>"},{"location":"user-guide/pg-format/","title":"Configuring pg_format","text":"<p><code>tapestry</code> relies on <code>pg_format</code> for formatting the rendered SQL files. This makes sure that,</p> <ul> <li>the rendered SQL files have consistent indentation</li> <li>you don't need to worry about SQL indentation when writing Jinja   templates</li> </ul> <p>However, <code>pg_format</code> is not a hard requirement for <code>tapestry</code>. If <code>pg_format</code> is not installed on your system at the time of running <code>tapestry init</code> command, the <code>formatter.pgFormatter</code> section will not be added in the auto-generated manifest file.</p> <p>The behavior of <code>pg_format</code> tool in the context of <code>tapestry</code> can be configured by adding a config file. The sample config file in the <code>pg_format</code> github repo can be used for reference.</p> <p>The default config file generated by <code>tapestry init</code> command is located at <code>.pg_format/config</code> (relative to the manifest file) and looks like this,</p> <pre><code># Lines between markers 'start(noformat)' and 'end(noformat)' will not\n# be formatted. If you want to customize the markers, you may do so by\n# modifying this parameter.\nplaceholder=start\\(noformat\\).+end\\(noformat\\)\n\n# Add a list of function to be formatted as PG internal\n# functions. Paths relative to the 'tapestry.toml' file will also work\n#extra-function=./.pg_format/functions.lst\n\n# Add a list of keywords to be formatted as PG internal keywords.\n# Paths relative to the 'tapestry.toml' file will also work\n#extra-keyword=./.pg_format/keywords.lst\n\n# -- DANGER ZONE --\n#\n# Please donot change the following config parameters. Tapestry may\n# not work otherwise.\nmultiline=1\nformat=text\noutput=\n</code></pre> <p>As you can see, the generated file itself is well documented.</p>"},{"location":"user-guide/pg-format/#disallowed-configuration","title":"Disallowed configuration","text":"<p>In the context of <code>tapestry</code>, some <code>pg_format</code> config params are disallowed (or they need to configured only in a certain way) for proper functioning of <code>tapestry</code>. These are explicitly defined with the intended value in the config file and annotated with <code>DANGER ZONE</code> warning in the comments. These must not be changed.</p>"},{"location":"user-guide/pg-format/#selectively-opting-out-of-sql-formatting","title":"Selectively opting out of SQL formatting","text":"<p>A commonly faced problem with formatting <code>pgTAP</code> tests using <code>pg_format</code> is that hard coded expected values get formatted in a way that could make the test case unreadable for humans.</p> <p>Example: Consider the following <code>pgTAP</code> test case written in a test template file,</p> <pre><code>SELECT results_eq(\n    'EXECUTE artists_long_songs(''Rock'', 2)',\n    $$VALUES\n        (22, 'Led Zeppelin'::varchar, '00:26:52.329'::interval),\n        (58, 'Deep Purple'::varchar, '00:19:56.094'::interval)\n    $$,\n    'Verify return value'\n);\n</code></pre> <p>By default <code>pg_format</code> would format the above SQL snippet as follows,</p> <pre><code>SELECT\n    results_eq ('EXECUTE artists_long_songs(''Rock'', 2)', $$\n    VALUES (22, 'Led Zeppelin'::varchar, '00:26:52.329'::interval), (58, 'Deep Purple'::varchar, '00:19:56.094'::interval) $$, 'Verify return value');\n</code></pre> <p>To retain the readability, we need to preserve the user's custom indentation. This is where the <code>placeholder</code> config param of <code>pg_format</code> is useful</p> <p>Note</p> <p>pg_format's <code>placeholder</code> config is not to be confused with <code>placeholder</code> config key in tapestry's manifest.</p> <p>This can be done by adding <code>noformat</code> markers before and after the snippet.</p> <pre><code>-- start(noformat)\nSELECT results_eq(\n    'EXECUTE artists_long_songs(''Rock'', 2)',\n    $$VALUES\n        (22, 'Led Zeppelin'::varchar, '00:26:52.329'::interval),\n        (58, 'Deep Purple'::varchar, '00:19:56.094'::interval)\n    $$,\n    'Verify return value'\n);\n-- end(noformat)\n</code></pre> <p>If you want to customize the markers for whatever reason, you can modify the <code>placeholder</code> param in the <code>pg_format</code> config file.</p>"},{"location":"user-guide/query-templates/","title":"Writing query templates","text":"<p>Query templates are Jinja template files. One query template can be used for generating multiple SQL queries. </p> <p>Often, an application needs to issue mostly similiar (or slightly different) queries to the db based on user input. Some examples: </p> <ul> <li>two queries that are exactly similar, except that one returns all   columns i.e. <code>*</code> whereas the other returns only selected rows</li> </ul> <ul> <li>two queries that are exactly the same, except that one has a limit</li> </ul> <ul> <li>multiple similar queries but different combination of <code>WHERE</code>   clauses</li> </ul> <p>Using Jinja templates, it's possible to write a single query template that can render multiple SQL queries. This is possible with a combination of Jinja variables and <code>{% if .. %}...{% endif %}</code> blocks. This is pretty much the main idea behind query templates.</p> <p>Query templates need to be defined in the manifest where we specify <code>all_conds</code> which is a set of \"cond\" vars that the template supports.</p> <p>Let's look at a query template from the chinook example distributed with the github repo.</p> <pre><code>SELECT\n    track.name as title,\n    artist.name as artist_name,\n    {% if cond__album_name %}\n      album.title as album_name,\n    {% endif %}\n    media_type.name as file_format\nFROM\n    album\n    JOIN artist USING (artist_id)\n    LEFT JOIN track USING (album_id)\n    JOIN media_type USING (media_type_id)\n\n{% if cond__artist or cond__file_format %}\n  WHERE\n  {% set num_conds = 0 %}\n  {% if cond__artist %}\n    artist.name = {{ placeholder('artist') }}\n    {% set num_conds = num_conds + 1 %}\n  {% endif %}\n\n  {% if cond__file_format %}\n    {% if num_conds &gt; 0 %}\n      AND\n    {% endif %}\n    media_type.name = {{ placeholder('file_format') }}\n    {% set num_conds = num_conds + 1 %}\n  {% endif %}\n{% endif %}\n;\n</code></pre> <p>The entry in the manifest file for the above <code>query_template</code> is,</p> <pre><code>[[query_templates]]\npath = \"songs_formats.sql.j2\"\nall_conds = [ \"artist\", \"file_format\", \"album_name\" ]\n</code></pre> <p>Because of the 3 <code>all_conds</code> defined in the manifest file, we have the following Jinja variables available inside the Jinja template.</p> <ol> <li><code>cond__artist</code></li> <li><code>cond__file_format</code></li> <li><code>cond__album_name</code></li> </ol> <p>The <code>cond__artist</code> and <code>cond__file_format</code> vars are used for conditionally including <code>WHERE</code> clauses. Because we want to add the <code>WHERE</code> clause only if either of the two vars are true, and because we want to add the <code>AND</code> operator only if both are true, nested <code>if</code> blocks are used and a temp \"counter\" variable <code>num_conds</code> is defined i.e. it's assigned to <code>0</code> and then incremented by 1 if the <code>cond__artist</code> var is true.</p> <p>The third variable <code>cond__album_name</code> is used for conditionally including a column in the returned result.</p>"},{"location":"user-guide/query-templates/#query","title":"Query","text":"<p>Now let's look at how a <code>query</code> associated with this template is defined in the manifest.</p> <pre><code>[[queries]]\nid = \"songs_formats@artist+album\"\ntemplate = \"songs_formats.sql.j2\"\nconds = [ \"artist\", \"album_name\" ]\noutput = \"songs_formats__artist__album.sql\"\n</code></pre> <p>In this query, only 2 of the 3 \"cond\" variables will be true.</p> <p>As a total of 3 <code>all_conds</code> values are supported by the query template, 8 different queries can be generated from it using different subsets of <code>all_conds</code>.</p> <pre><code>[ ]\n[ \"artists\" ]\n[ \"artists\", \"file_format\" ]\n[ \"artists\", \"album_name\" ]\n[ \"file_format\" ]\n[ \"file_format\", \"album_name\" ]\n[ \"album_name\" ]\n[ \"artist\", \"file_format\", \"album_name\" ]\n</code></pre>"},{"location":"user-guide/test-templates/","title":"Test templates","text":"<p>Just like <code>query_templates</code>, <code>test_templates</code> are also Jinja template files. But while one query template could be used to generate several queries, one test template can be used to generate only one <code>pgTAP</code> test file.</p> <p>However, many test templates can be associated with a single query. In other words, if multiple <code>pgTAP</code> test suites are to be written for the same query, that's possible.</p> <p>The test syntax is SQL only but with some additional functions installed by <code>pgTAP</code>. If you are not familiar with <code>pgTAP</code> you can go through it's documentation. Important thing to note is that the Jinja variable <code>{{ prepared_statement }}</code> is made available to every test template, and at the time of rendering, it will expand to the actual query.</p> <p>Let's look at a templates from the chinook example.</p> <p>Refer to the test template <code>songs_formats-afa_test.sql.j2</code>. The first few lines are:</p> <pre><code>PREPARE song_formats (varchar, varchar) AS\n{{ prepared_statement }};\n</code></pre> <p>Here we're using the <code>prepared_statement</code> Jinja variable to create a prepared statement for the user session. The name of the prepared statement is <code>song_formats</code> and it takes two positional args, both of type <code>varchar</code>.</p> <p>Later in the same file, the prepared statement is executed as part of a <code>pgTAP</code> test case,</p> <pre><code>SELECT results_eq(\n    'EXECUTE song_formats(''Iron Maiden'', ''Protected AAC audio file'')',\n    $$VALUES\n      ...\n      ...\n    $$,\n    'Verify return value'\n);\n</code></pre> <p>Check the <code>songs_formats-afa_test.sql</code> output file to see how the actual test file looks like.</p> <p>Note</p> <p>Note that the SQL query that <code>prepared_statement</code> Jinja var expands to will always have <code>posargs</code> based placeholders, even if the <code>placeholder</code> config in manifest file is set to <code>variables</code>. That's the reason why the Jinja var is named <code>prepared_statement</code></p>"},{"location":"user-guide/test-templates/#function-instead-of-ps","title":"Function instead of PS","text":"<p>Sometimes it's tedious to test for result sets returned by the query. In such cases, it helps to manipulate the result returned by the query and compare a derived property. E.g. If a query results too many rows, it's easier to compare the count than the actual values in the rows.</p> <p>One limitation of prepared statements and the <code>EXECUTE</code> syntax for executing them is that it's not sub-query friendly i.e. it's not possible to execute a prepared statement as part of another query.</p> <p>The following is NOT valid SQL</p> <pre><code>SELECT\n    count(*)\nFROM (EXECUTE song_formats ('Iron Maiden', 'Protected AAC audio file'));\n</code></pre> <p>In such cases, we can define a SQL function using the same <code>prepared_statement</code> Jinja variable.</p> <p>An example of this can be found in the chinook example - <code>all_artists_long_songs_test.sql.j2</code></p> <pre><code>CREATE OR REPLACE FUNCTION all_artists_long_songs ()\nRETURNS SETOF record\nAS $$\n{{ prepared_statement }}\n$$ LANGUAGE sql;\n\nBEGIN;\nSELECT\n    plan (1);\n\n-- start(noformat)\n-- Run the tests.\nSELECT is(count(*), 204::bigint) from all_artists_long_songs() AS (artist_id int, name text, duration interval);\n-- Finish the tests and clean up.\n-- end(noformat)\n\nSELECT\n    *\nFROM\n    finish ();\nROLLBACK;\n</code></pre>"},{"location":"user-guide/test-templates/#test-fixtures","title":"Test fixtures","text":"<p>When it comes to automated tests, It's a very common requirement to setup some test data to be able to write test cases. <code>pgTAP</code> tests are not any different. In case of <code>pgTAP</code> one needs to create test data in the database.</p> <p>Since <code>pgTAP</code> tests are just SQL files, test data creation can be done using SQL itself in the same file. Reusable setup code can also be extracted into SQL functions that can be created as part of importing the database schema.</p> <p>The chinook directory doesn't include an example of this. But here's an example from one of my real projects that uses <code>tapestry</code>.</p> <p>In my project, there are two entities <code>categories</code> and <code>items</code> (having tables of the same names) with <code>one-to-many</code> relationship i.e. one category can have multiple items.</p> <p>In several <code>pgTAP</code> tests, a few categories and items need to be created. To do this, a function is defined as follows,</p> <pre><code>CREATE OR REPLACE FUNCTION tapestry.setup_category_n_items (cat_id varchar, item_idx_start integer, item_idx_end integer)\n    RETURNS void\n    AS $$\n    INSERT INTO categories (id, name)\n        VALUES (cat_id, initcap(replace(cat_id, '-', ' ')));\n    INSERT INTO items (id, name, category_id)\n    SELECT\n        'item-' || t AS id,\n        'Item ' || t AS name,\n        cat_id AS category_id\n    FROM\n        generate_series(item_idx_start, item_idx_end) t;\n$$\nLANGUAGE sql;\n</code></pre> <p>And then it's used in <code>pgTAP</code> tests like this, </p> <pre><code>...\n\nBEGIN;\nSELECT plan(1);\n\n-- Fixtures\n-- create 2 categories, 'cat-a' and 'cat-b' each having 5 items\nSELECT\n    tapestry.setup_category_n_items ('cat-a', 1, 5);\nSELECT\n    tapestry.setup_category_n_items ('cat-b', 6, 10);\n\n-- Test cases\n\n...\n</code></pre>"}]}