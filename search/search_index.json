{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tapestry","text":"<p>Tapestry is a framework for writing (postgres)SQL queries and (pgTAP) tests using Jinja templates.</p> <p>Tapestry is written in Rust but it can be used with applications written in any programming language. It's purely a command line tool that renders Jinja templates into SQL files. How to load the resulting SQL code into memory and use it at runtime is entirely up to the application.</p> <p>This approach of loading SQL from files is not new. There are existing libraries such as yesql, hugsql (Clojure), aiosql (Python) etc. that provide excellent abstractions for it. In absence of such a lib for the language of your choice, it shouldn't take more than a few lines of code to implement a simple file loader. In Rust apps, I simply use the <code>include_str!</code> macro.</p> <p>One limitation is that <code>tapestry</code> can only be used with PostgreSQL, because of the tight coupling with <code>pgTAP</code>.</p> <p>You may find this tool useful if,</p> <ol> <li> <p>you prefer direct SQL queries over ORMs or query builders to    interact with RDBMS from application code</p> </li> <li> <p>you are not averse to the idea of having (reasonable amount of)    business logic inside SQL queries</p> </li> </ol> <p>In fact, if you have had concerns about point 2 i.e. having business logic in SQL queries, perhaps <code>tapestry</code> addresses some of those concerns. Learn more about the rationale behind this tool.</p> <p>If you prefer a hands-on introduction, check the Getting started page.</p>"},{"location":"rationale/","title":"Rationale","text":""},{"location":"rationale/#problems-with-using-raw-sql-in-application-code","title":"Problems with using raw SQL in application code","text":"<p>For many years, I've believed that,</p> <ol> <li> <p>it's a good idea to write raw SQL queries (safely) for interacting    with an RDBMS from application code using libs such as yesql,    aiosql etc.</p> </li> <li> <p>it's ok to add reasonable amount of business logic in the SQL    queries, rather than using SQL merely for data access.</p> </li> </ol> <p>Still, I've had concerns about using these ideas in practice, specially in serious projects.</p>"},{"location":"rationale/#unit-testing-sql-queries","title":"Unit testing SQL queries","text":"<p>Typically, unit tests are written against application code. As more and more business logic gets moved out of the application and into SQL queries, the queries become longer and more complex. In contrast, the application code is reduced to just making db calls using the driver/client library. At this point, it makes more sense to test the queries than the application code.</p> <p>Fortunately for PostgreSQL, we have the excellent <code>pgTAP</code> extension that makes it easy to write unit tests for raw queries. Just like the raw queries themselves, <code>pgTAP</code> tests are typically defined in SQL files. But since the query and the tests are in separate files, it's possible that one modifies the SQL query, but forgets to update the tests, and the tests could still pass!</p> <p>How to ensure that the tests actually run the exact same query that's being run by the application?</p>"},{"location":"rationale/#maintenance-overhead-of-multiple-slightly-differing-queries","title":"Maintenance overhead of multiple, slightly differing queries","text":"<p>An application often needs to issue similar queries but returning different set of columns or with different <code>WHERE</code> clauses based on user input. In such cases, a unique query needs to be written and maintained for every combination of the input parameters.  This could result in multiple queries that differ only slightly. If some core part of the query needs a change, one needs to remember to update multiple SQL files.</p> <p>Moreover, higher level abstractions (e.g. yesql etc.) usually cache queries in memory, so they require the queries to be given a name or an identifier. Since the queries differ only slightly, trying to give them unique names can be tricky. </p>"},{"location":"rationale/#how-tapestry-solves-it","title":"How tapestry solves it?","text":"<p>Tapestry was built to specifically address the above problems and concerns. It does so by generating actual queries as well as <code>pgTAP</code> test files from Jinja templates, instead of having the user write raw SQL.</p>"},{"location":"rationale/#query-templates","title":"Query templates","text":"<ul> <li>You write query templates instead of raw queries</li> <li>Multiple queries can be mapped to the same query template. Mapping   is defined in the <code>tapestry.toml</code> manifest file.</li> <li>User defined Jinja variables can be used for conditionally adding or   omitting parts of the query e.g. a <code>WHERE</code> condition or column to   return. These Jinja vars are also defined in the manifest file.</li> <li>Thus, it's easy to generate and maintain multiple queries that are   similar enough to be defined using a single query template.</li> </ul>"},{"location":"rationale/#test-templates","title":"Test templates","text":"<ul> <li><code>pgTAP</code> tests are also written as Jinja templates</li> <li>Test templates are mapped to queries, again in the manifest   file. One query can be mapped to multiple test templates.</li> <li>When tapestry renders the final test file from a test template, a   special Jinja variable <code>{{ prepared_statement }}</code> gets expanded to   the actual query that the test template is mapped to.</li> <li>This way, the generated test SQL file is guaranteed to have the   exact same query which is used by the application code.</li> </ul>"},{"location":"rationale/#naming-conventions","title":"Naming conventions","text":"<p>Tapestry suggests some conventions for naming queries consistently but they are not mandatory.</p>"},{"location":"user-guide/","title":"Overview","text":"<p>Tapestry is built to address the peculiar concerns that I've had about using libraries such as yesql, aiosql and the likes. While I agree with the philosophy behind such libs\u2014that SQL code is better written as SQL directly rather than building it through ORMs, query builders or worse, by string interpolation or concatenation\u2014I've had some concerns about using the approach in practice.</p> <p>To understand more about the problems and how tapestry addresses them, please check the Rationale page.</p> <p>The general idea behind this tool is, instead of users writing raw SQL queries, have them write Jinja templates from which SQL queries as well as pgTAP tests can be generated.</p> <p>Here is a high level overview of how you'd use tapestry in your project:</p> <ol> <li> <p>Create a directory inside your project where the templates will be    located. The <code>tapestry init</code> command does this    for you.</p> </li> <li> <p>Add some information in the <code>tapestry.toml</code> manifest    file:</p> <ol> <li>Lists of query templates, queries and test templates along with     the mappings between them</li> <li>Location of query templates and test templates (input files)</li> <li>Location of where the output files are to be created</li> <li>etc...</li> </ol> </li> <li> <p>Run <code>tapestry render</code> command to generate    the SQL files, both for queries as well as tests.</p> </li> <li> <p>Use a lib such as yesql, aiosql etc. to load the queries rendered    by the previous step into the application runtime.</p> </li> <li> <p>Use <code>pg_prove</code> to run the pgTAP tests, preferably as part of    CD/CI. You'd need to implement some kind of automation for    this. The github repo also includes a docker image that may help    with this.</p> </li> </ol>"},{"location":"user-guide/cd-ci/","title":"CD/CI integration","text":"<p>If you are using tapestry in a real project, it's a good idea to integrate it with your CD/CI workflows for the following purposes:</p>"},{"location":"user-guide/cd-ci/#ensuring-that-the-generated-sql-files-are-not-stale","title":"Ensuring that the generated SQL files are not stale","text":"<p>Because of how tapestry works, you'd typically commit the generated output files to version control. It then becomes important to ensure that the <code>tapestry render</code> command is executed every time before a release.</p> <p>To help with this, tapestry provides the <code>--assert-no-changes</code> option for the <code>status</code> command.</p> <pre><code>$ tapestry status --assert-no-changes\nQuery: modified: output/queries/artists_long_songs.sql\n  Test: modified: output/tests/all_artists_long_songs_count_test.sql\nQuery: unchanged: output/queries/artists_long_songs-limit.sql\nQuery: unchanged: output/queries/artists_long_songs-genre-limit.sql\n  Test: unchanged: output/tests/artists_long_songs-genre-limit_test.sql\nQuery: unchanged: output/queries/songs_formats-artist-album.sql\nQuery: unchanged: output/queries/songs_formats-artist-file_format-album.sql\n  Test: unchanged: output/tests/songs_formats-afa_test.sql\n$ echo $?\n1\n</code></pre> <p>If a commit is pushed without re-rendering the output files, the command will fail.</p>"},{"location":"user-guide/cd-ci/#ensuring-test-coverage","title":"Ensuring test coverage","text":"<p>The <code>coverage</code> command supports an option <code>--fail-under</code> that can be used to make the command return with non-zero exit code if the code coverage score (percentage of queries that have at least 1 test) is below the provided threshold. Example:</p> <pre><code>$ tapestry coverage --fail-under=90 &gt; /dev/null\n$ echo $?\n1\n</code></pre> <p>If a commit adds new SQL templates and queries but skips the tests, causing the test coverage to drop below the standard, then this command will fail.</p>"},{"location":"user-guide/cd-ci/#running-pgtap-tests","title":"Running pgTAP tests","text":"<p>How to run the generated pgTAP tests against a blank postgres database largely depends on your CD/CI and database setup. So tapestry doesn't aim to provide a direct command for this. But you may be able to use the docker/podman based workflow as a starting point and adapt it to your CD/CI platform.</p>"},{"location":"user-guide/commands/","title":"Commands","text":"<p>This page documents all commands in the <code>tapestry</code> CLI.</p> <p>Note that for all commands except <code>init</code>, this tool will try to read the <code>tapestry.toml</code> manifest file in the current directory and will fail if it's not found. This implies that all <code>tapestry</code> commands except <code>init</code> must be executed from within the \"tapestry project\" root dir.</p>"},{"location":"user-guide/commands/#init","title":"init","text":"<p>The <code>init</code> command can be used for scaffolding a new <code>tapestry</code> \"project\". It will create the directory structure and also write a bare minimum manifest file for us. In a real project, you'd run this command from within the main project directory, so that the files can be committed to the same repo. Example:</p> <p>Running the following command,</p> <pre><code>tapestry init myproj\n</code></pre> <p>.. will create the following directory structure</p> <pre><code>$ cd myproj\n$ tree -a --charset=ascii .\n.\n|-- .pg_format\n|   `-- config\n|-- tapestry.toml\n`-- templates\n    |-- queries\n    `-- tests\n</code></pre>"},{"location":"user-guide/commands/#validate","title":"validate","text":"<p>The <code>validate</code> command checks and ensures that the manifest file is valid. Additionally it also verifies that the paths referenced in the manifest actually exist and are readable.</p>"},{"location":"user-guide/commands/#render","title":"render","text":"<p>The <code>render</code> command renders all the template files into SQL files.</p>"},{"location":"user-guide/commands/#status","title":"status","text":"<p>The <code>status</code> command can be used to preview the effect of running <code>tapestry render</code> command. It will list which output files will be added, modified or remain unchanged if the <code>render</code> command is run. This command will not actually write the output files.</p> <p>Output of running <code>tapestry status</code> inside the examples/chinook directory:</p> <pre><code>$ tapestry status\nQuery: unchanged: output/queries/artists_long_songs.sql\n  Test: unchanged: output/tests/all_artists_long_songs_count_test.sql\nQuery: unchanged: output/queries/artists_long_songs-limit.sql\nQuery: unchanged: output/queries/artists_long_songs-genre-limit.sql\n  Test: unchanged: output/tests/artists_long_songs-genre-limit_test.sql\nQuery: unchanged: output/queries/songs_formats-artist-album.sql\nQuery: unchanged: output/queries/songs_formats-artist-file_format-album.sql\n  Test: unchanged: output/tests/songs_formats-afa_test.sql\n</code></pre> <p>In a way, it's sort of a dry run for the <code>render</code> command.</p>"},{"location":"user-guide/commands/#-assert-no-changes","title":"<code>--assert-no-changes</code>","text":"<p>A more effective use of this command though is with the <code>--assert-no-changes</code> flag which will cause it to exit with non-zero code if it finds any output files that would get added or modified upon rendering. It's recommended to be run as part of CD/CI, to prevent the user from mistakenly releasing code without rendering the templates.</p>"},{"location":"user-guide/commands/#summary","title":"summary","text":"<p>The <code>summary</code> command prints a tabular summary of all queries along with their associated (query) templates and tests.</p>"},{"location":"user-guide/commands/#-all","title":"<code>--all</code>","text":"<p>When <code>--all</code> option is specified with this command, the summary will include query and test files inside <code>queries_output_dir</code> and <code>tests_output_dir</code> respectively that are not added to the manifest.</p> <p>Note</p> <p>There are legit use cases for having files in the query and test output directories that are not added to the manifest Examples:</p> <ol> <li> <p>queries that don't need any tests but need to be stored in the same directory as other queries, so that yesql, aiosql libs can load all of them together.</p> </li> <li> <p>Existing queries which are not yet migrated to tapestry (gradual migration strategy).</p> </li> <li> <p>pgTAP tests written for stored procedures, views, schema etc. that need to be stored in the same directory as other tests, so that all tests can be run together.</p> </li> </ol>"},{"location":"user-guide/commands/#coverage","title":"coverage","text":"<p>The <code>coverage</code> command prints a list of queries along with the no. of tests (i.e. <code>pgTAP</code> test files) for them. It also prints a coverage <code>score</code> which is calculated as the percentage of queries that have at least 1 test.</p> <p>Example: Following is the output of running <code>tapestry coverage</code> inside the examples/chinook dir.</p> <pre><code>$ tapestry coverage\n+----------------------------------------+------------------------------------+\n| Query                                  | Has tests?                         |\n+=============================================================================+\n| artists_long_songs                     | Yes (1)                            |\n|----------------------------------------+------------------------------------|\n| artists_long_songs*limit               | No                                 |\n|----------------------------------------+------------------------------------|\n| artists_long_songs@genre*limit         | Yes (1)                            |\n|----------------------------------------+------------------------------------|\n| songs_formats@artist+album             | No                                 |\n|----------------------------------------+------------------------------------|\n| songs_formats@artist&amp;file_format+album | Yes (1)                            |\n|----------------------------------------+------------------------------------|\n| Total                                  | 60.00%                             |\n|                                        | (3/5 queries have at least 1 test) |\n+----------------------------------------+------------------------------------+\n</code></pre>"},{"location":"user-guide/commands/#-fail-under","title":"<code>--fail-under</code>","text":"<p>By specifying the <code>--fail-under</code> option, the <code>coverage</code> command can be made to exit with non-zero return code if the percentage coverage is below a threshold.</p> <pre><code>$ tapestry coverage --fail-under=90 &gt; /dev/null\n$ echo $?\n1\n</code></pre> <p>The value of <code>--fail-under</code> option must be an integer between 0 and 100.</p> <p>The above command can be run as part of CD/CI to ensure that the test coverage doesn't fall below a certain threshold.</p>"},{"location":"user-guide/docker/","title":"Docker/Podman","text":""},{"location":"user-guide/docker/#container-based-workflow-to-run-pgtap-tests","title":"Container based workflow to run pgTAP tests","text":"<p><code>tapestry</code> only generates SQL files for queries and <code>pgTAP</code> tests. To be able to run the tests you need to install and setup:</p> <ol> <li>PostgreSQL server</li> <li><code>pgTAP</code>, which is a postgres extension</li> <li><code>pg_prove</code>, which is a command line test runner/harness for <code>pgTAP</code>    tests</li> </ol> <p>While these can be setup manually, the <code>tapestry</code> github repo provides a docker based workflow for easily running tests generated by <code>tapestry</code> against a temporary pg database.</p> <p>The relevant files can be found inside the <code>docker</code> directory under project root.</p> <p>Note</p> <p>I use podman instead of docker for managing containers. Hence all the docker commands in this doc have been actually tested using podman only. As podman claims CLI compatibility with docker, I am assuming that replacing <code>podman</code> with <code>docker</code> in the below mentioned commands should just work. If that's not the case, please create an issue on github.</p>"},{"location":"user-guide/docker/#build-the-docker-image","title":"Build the docker image","text":"<pre><code>cd docker\npodman build -t tapestry-testbed -f ./Dockerfile\n</code></pre>"},{"location":"user-guide/docker/#start-container-for-postgres-process","title":"Start container for postgres process","text":"<pre><code>podman run --name taptestbed \\\n    --env POSTGRES_PASSWORD=secret \\\n    -d \\\n    -p 5432:5432 \\\n    tapestry-testbed:latest\n</code></pre> <p>Verify that the <code>5432</code> port is reachable from the host machine.</p> <pre><code>nc -vz localhost 5432\n</code></pre> <p>The above <code>podman run</code> command will create a container and start it. After that you can manage the container using the <code>podman container</code> commands</p> <pre><code>podman container stop taptestbed\npodman container start taptestbed\n</code></pre>"},{"location":"user-guide/docker/#running-tests","title":"Running tests","text":"<p>The <code>pg_prove</code> executable is part of the image that we have built. But to be able to run tests inside the container, we need to make the database schema and the test SQL files accessible to it. For this we bind mount a volume into the container when running it, using the <code>--volume</code> option.</p> <p>The container image has a bash script <code>run-tests</code> installed into it which picks up the schema and the test SQL files from the mounted dir.</p> <p>The <code>run-tests</code> scripts makes certain assumptions about organization of files inside the mounted dir. Inside the container, the dir must be mounted at <code>/tmp/tapestry-data/</code> and there must be be two sub directories under it:</p> <ol> <li> <p><code>schema</code>: All SQL files inside this dir will be executed against    the database server in lexicographical order to setup a temporary    test database.</p> </li> <li> <p><code>tests</code>: All SQL files inside this dir will be considered as tests    and specified as arguments to the <code>pg_prove</code> command.</p> </li> </ol> <p>Once such a local directory is created, you can run the tests as follows,</p> <pre><code>podman run -it \\\n    --rm \\\n    --network podman \\\n    -v ~/tapestry-data/:/tmp/tapestry-data/ \\\n    --env PGPASSWORD=secret \\\n    --env PGHOST=$(podman container inspect -f '{{.NetworkSettings.IPAddress}}' taptestbed) \\\n    tapestry-testbed:latest \\\n    run-tests -c -d temptestdb\n</code></pre> <p>In the above command, <code>temptestdb</code> is the name of the db that will be created by the <code>run-tests</code> script. If your schema files themselves take care of creating the db, then you can specify that as the name and omit the <code>-c</code> flag.</p> <p>To know more about the usage of <code>run-tests</code> script, run,</p> <pre><code>podman run -it --rm tapestry-testbed:latest run-tests --help\n</code></pre>"},{"location":"user-guide/formatting/","title":"Formatting SQL","text":"<p>If your SQL queries are even moderately complex, you'd want them to be formatted, mainly for readability. But with tapestry, you don't write the actual SQL by hand. Instead you write SQL code in bits and pieces within Jinja2 templates. Trying to get the SQL formatted the way you like using jinja2's whitespace control doesn't work well.</p> <p>For that reason, tapestry takes care of formatting SQL at the time of rendering. For that, it supports a bunch of popular SQL formatting tools that the user may already have installed on their system. The currently supported formatting tools are:</p> <ol> <li>sqlformat (inbuilt)</li> <li>pg_format (PL/pgSQL + Perl)</li> <li>sql-formatter (Javascript)</li> <li>sqlfluff (Python)</li> </ol> <p>All except the first one are external tools that tapestry \"shells-out\" to. Hence they are expected to be installed on your system.</p> <p>Tapestry also comes with it's own inbuilt formatter that can be used in case none of the above tools are installed. It's powered by the sqlformat-rs crate. You may choose this if you don't prefer to install an additional system level dependency. Although the level of config supported by sqlformat is quite rudimentary.</p>"},{"location":"user-guide/formatting/#selecting-a-formatter","title":"Selecting a formatter","text":"<p>When you initialize a new tapestry project by running <code>tapestry init</code>, it will try to find if any supported formatting tools are installed on your system. Based on that, it will show a prompt for selecting the tool of your choice.</p> <pre><code>$ tapestry init myproject\n? Choose an SQL formatter\n  None (no formatting)\n&gt; sqlformat (built-in)\n  pg_format\n  sql-formatter\n  sqlfluff\n[The above SQL formatters were found on your system and available for use. Choose one or None to opt out of formatting]\n</code></pre> <p>The option selected by default is <code>sqlformat</code> which is the aforementioned inbuilt formatter.</p> <p><code>None</code> is also an option in case you'd like to opt out of SQL formatting. In that case, tapestry will skip the formatting step altogether.</p>"},{"location":"user-guide/formatting/#configuring-the-formatter","title":"Configuring the formatter","text":"<ul> <li>sqlformat</li> </ul> <ul> <li>pg_format</li> </ul> <ul> <li>sql-formatter</li> </ul> <ul> <li>sqlfluff</li> </ul>"},{"location":"user-guide/formatting/#support-for-more-formatters","title":"Support for more formatters","text":"<p>The underlying formatting component of tapestry is designed to be extensible, so that support for more tools can be added without much effort. If you want a particular SQL formatting tool to be supported, feel free to open an issue or a PR on github.</p>"},{"location":"user-guide/getting-started/","title":"Getting started","text":"<p>This tutorial is to help you get started with tapestry. It's assumed that the following software is installed on your system:</p> <ul> <li><code>tapestry</code></li> <li><code>pg_format</code></li> <li>a working installation of PostgreSQL (official   docs)</li> <li><code>pgTAP</code> and <code>pg_prove</code></li> </ul>"},{"location":"user-guide/getting-started/#sample-database","title":"Sample database","text":"<p>For this tutorial, we'll use the chinook sample database. Download and import it as follows,</p> <pre><code>wget -P /tmp/ https://github.com/lerocha/chinook-database/releases/download/v1.4.5/Chinook_PostgreSql_SerialPKs.sql\ncreatedb chinook\npsql -d chinook -f /tmp/Chinook_PostgreSql_SerialPKs.sql\n</code></pre>"},{"location":"user-guide/getting-started/#init","title":"Init","text":"<p>We'll start by running the <code>tapestry init</code> command, which will create the directory structure and also write a bare minimum manifest file for us. In a real project, you'd run this command from within the main project directory, so that the files can be committed to the same repo. But for this tutorial, you can run it from any suitable location e.g. the home dir <code>~/</code></p> <pre><code>cd ~/\ntapestry init chinook\n</code></pre> <p>New in version 0.2.0</p> <p>Running <code>init</code> will prompt you to choose an sql formatter.</p> <pre><code>? Choose an SQL formatter\n  None (no formatting)\n  sqlformat (built-in)\n&gt; pg_format\n  sql-formatter\n  sqlfluff\n[The above SQL formatters were found on your system and available for use. Choose one or None to opt out of formatting]\n</code></pre> <p>This example assumes that <code>pg_format</code> is chosen as the preferred formatter. For more details about SQL formatting support, see SQL formatting.</p> <p>This will create a directory named <code>chinook</code> with following structure,</p> <pre><code>$ cd chinook\n$ tree -a --charset=ascii .\n.\n|-- .pg_format\n|   `-- config\n|-- tapestry.toml\n`-- templates\n    |-- queries\n    `-- tests\n</code></pre> <p>Let's look at the <code>tapestry.toml</code> manifest file that has been created (I've stripped out some comments for conciseness)</p> <pre><code>$ cat tapestry.toml\nplaceholder = \"posargs\"\n\nquery_templates_dir = \"templates/queries\"\ntest_templates_dir = \"templates/tests\"\n\nqueries_output_dir = \"output/queries\"\ntests_output_dir = \"output/tests\"\n\n[formatter.pgFormatter]\nexec_path = \"pg_format\"\nconf_path = \"./.pg_format/config\"\n\n[name_tagger]\nstyle = \"kebab-case\"\n\n# [[query_templates]]\n\n# [[queries]]\n\n# [[test_templates]]\n</code></pre> <p><code>placeholder</code> defines the style of generated queries. Default is <code>posargs</code> (positional arguments) which will generate queries with <code>$1</code>, <code>$2</code> etc as the placeholders. These are suitable for defining prepared statements.</p> <p>Then there are four toml keys for defining directories,</p> <ol> <li> <p><code>query_templates_dir</code> is where the query templates will be located</p> </li> <li> <p><code>test_templates_dir</code> is where the test templates will be located</p> </li> <li> <p><code>queries_output_dir</code> is where the SQL files for queries will be    generated</p> </li> <li> <p><code>tests_output_dir</code> is where the SQL files for pgTAP tests will be    generated.</p> </li> </ol> <p>All directory paths are relative to the manifest file.</p> <p>You may have noticed that the <code>init</code> command created only the templates dirs. <code>output</code> dirs will be created when <code>tapestry render</code> is called for the first time.</p> <p>The <code>init</code> command has also created a <code>pg_format</code> config file for us. This is because it found the <code>pg_format</code> executable on <code>PATH</code>. Refer to the <code>pg_format</code> section for more details.</p> <p>Finally, <code>name_tagger</code> has been configured with <code>kebab-case</code> as the <code>style</code>.</p>"},{"location":"user-guide/getting-started/#adding-a-query_template-to-generate-queries","title":"Adding a query_template to generate queries","text":"<p>Now we'll define a query template. But before that, you might want to get yourself familiar with the chinook database's schema.</p> <p>Suppose we have an imaginary application built on top of the chinook database in which the following queries need to be run,</p> <ol> <li> <p>list all artists with their longest songs</p> </li> <li> <p>list top 10 artists having longest songs</p> </li> <li> <p>list top 5 artists having longest songs, and of a specific genre</p> </li> </ol> <p>As you can see, we'd need different queries for each of the 3 requirements, but all have a common logic of finding longest songs per artist. Using Jinja syntax, we can write a query template that covers all 3 cases as follows,</p> <pre><code>SELECT\n    ar.artist_id,\n    ar.name,\n    max(milliseconds) * interval '1 ms' AS duration\nFROM\n    track t\n    INNER JOIN album al USING (album_id)\n    INNER JOIN artist ar USING (artist_id)\n{% if cond__genre %}\n    INNER JOIN genre g USING (genre_id)\n  WHERE\n  g.name = {{ placeholder('genre') }}\n{% endif %}\nGROUP BY\n    ar.artist_id\nORDER BY\n-- Descending order because we want the top artists\n    duration DESC\n{% if cond__limit %}\n  LIMIT {{ placeholder('limit') }}\n{% endif %}\n;\n</code></pre> <p>We've used some custom Jinja variables for selectively including parts of SQL in the query. These need to be prefixed with <code>cond__</code> and have to be defined in the manifest file (we'll come to that a bit later).</p> <p>We have also used the custom Jinja function <code>placeholder</code> which takes one arg and expands to a placeholder in the actual query. This will be clear once we render the queries.</p> <p>Let's save the above query template to the file <code>templates/queries/artists_long_songs.sql.j2</code>.</p> <p>And now we'll proceed to defining the query_template and the queries that it can generate in the manifest file. Edit the <code>tapestry.toml</code> file by appending the following lines to it.</p> <pre><code>[[query_templates]]\npath = \"artists_long_songs.sql.j2\"\nall_conds = [ \"genre\", \"limit\" ]\n</code></pre> <p>To define a <code>query_template</code> we need to specify 2 keys:</p> <ol> <li> <p><code>path</code> i.e. where the template file is located relative to the    <code>query_templates_dir</code> defined earlier in the manifest. <code>path</code>    itself is considered as the unique identifier for the query    template.</p> </li> <li> <p><code>all_conds</code> is a set of values that will be converted to <code>cond__</code>    Jinja variables. In this case it means there are two <code>cond__</code> Jinja    templates supported by the template - <code>cond__genre</code> and    <code>cond__limit</code>. Note that they are defined in the manifest without    the <code>cond__</code> suffix.</p> </li> </ol> <p>We can now define three different queries that map to the same query_template</p> <pre><code>[[queries]]\nid = \"artists_long_songs\"\ntemplate = \"artists_long_songs.sql.j2\"\nconds = []\n\n[[queries]]\nid = \"artists_long_songs*limit\"\ntemplate = \"artists_long_songs.sql.j2\"\nconds = [ \"limit\" ]\n\n[[queries]]\nid = \"artists_long_songs@genre*limit\"\ntemplate = \"artists_long_songs.sql.j2\"\nconds = [ \"genre\", \"limit\" ]\n</code></pre> <p>To define a query, we need to specify 3 keys,</p> <ol> <li> <p><code>id</code> is an identifier for the query. Notice that we're following a    naming convention by using special chars <code>@</code> and <code>*</code>. Read more    about Query naming conventions.</p> </li> <li> <p><code>template</code> is reference to the query template that we defined    earlier.</p> </li> <li> <p><code>conds</code> is a subset of the <code>all_conds</code> key that's defined for the    linked query template. In the context of this query, only the    corresponding <code>cond__</code> Jinja variables will have the value <code>true</code>,    and the rest of them will be <code>false</code>.</p> </li> </ol> <p>We've defined three queries that use the same template. In the first query, both the <code>conds</code> that the template supports i.e. \"genre\" and \"limit\" are false. In the second query, \"limit\" is true but \"genre\" is false. In the third query, both \"genre\" and \"limit\" are true. Queries will be rendered based on these variables and the <code>{% if cond__.. %}</code> expressions in the template.</p> <p>Don't worry if all this doesn't make much sense at this point. Things will be clear when we'll run <code>tapestry render</code> shortly.</p>"},{"location":"user-guide/getting-started/#rendering","title":"Rendering","text":"<p>Now let's run the <code>tapestry render</code> command.</p> <pre><code>tapestry render\n</code></pre> <p>And you'll notice some files created in our directory.</p> <pre><code>$ tree -a --charset=ascii .\n.\n|-- .pg_format\n|   `-- config\n|-- output\n|   |-- queries\n|   |   |-- artists_long_songs-genre-limit.sql\n|   |   |-- artists_long_songs-limit.sql\n|   |   `-- artists_long_songs.sql\n|   `-- tests\n|-- tapestry.toml\n`-- templates\n    |-- queries\n    |   `-- artists_long_songs.sql.j2\n    `-- tests\n</code></pre> <p>Here is what the generated output files look like:</p> artists_long_songs.sqlartists_long_songs-limit.sqlartists_long_songs-genre-limit.sql <pre><code>-- name: artists-long-songs\nSELECT\n    ar.artist_id,\n    ar.name,\n    max(milliseconds) * interval '1 ms' AS duration\nFROM\n    track t\n    INNER JOIN album al USING (album_id)\n    INNER JOIN artist ar USING (artist_id)\nGROUP BY\n    ar.artist_id\nORDER BY\n    -- Descending order because we want the top artists\n    duration DESC;\n</code></pre> <pre><code>-- name: artists-long-songs-limit\nSELECT\n    ar.artist_id,\n    ar.name,\n    max(milliseconds) * interval '1 ms' AS duration\nFROM\n    track t\n    INNER JOIN album al USING (album_id)\n    INNER JOIN artist ar USING (artist_id)\nGROUP BY\n    ar.artist_id\nORDER BY\n    -- Descending order because we want the top artists\n    duration DESC\nLIMIT $1;\n</code></pre> <pre><code>-- name: artists-long-songs-genre-limit\nSELECT\n    ar.artist_id,\n    ar.name,\n    max(milliseconds) * interval '1 ms' AS duration\nFROM\n    track t\n    INNER JOIN album al USING (album_id)\n    INNER JOIN artist ar USING (artist_id)\n    INNER JOIN genre g USING (genre_id)\nWHERE\n    g.name = $1\nGROUP BY\n    ar.artist_id\nORDER BY\n    -- Descending order because we want the top artists\n    duration DESC\nLIMIT $2;\n</code></pre> <p>The SQL comments before the SQL with name of the query are generated by <code>name_tagger</code> added to the manifest. Learn more about Name tagging.</p> <p>Also notice that the output SQL is formatted by <code>pg_format</code>.</p>"},{"location":"user-guide/getting-started/#adding-a-test_template","title":"Adding a test_template","text":"<p>Now that we've defined and rendered queries, let's add <code>test_template</code>. Again there are two changes required - an entry in the manifest file and the Jinja template itself.</p> <p>Add the following lines to the manifest file.</p> <pre><code>[[test_templates]]\nquery = \"artists_long_songs@genre*limit\"\npath = \"artists_long_songs-genre-limit_test.sql.j2\"\n</code></pre> <p>Here we're referencing the query <code>artists_long_songs@genre*limit</code> hence this test is meant for that query. The <code>path</code> key points to a test template file that we need to create. So let's create the file <code>templates/tests/artists_long_songs-genre-limit_test.sql.j2</code> with the following contents:</p> <pre><code>PREPARE artists_long_songs(varchar, int) AS\n{{ prepared_statement }};\n\nBEGIN;\nSELECT\n    plan (1);\n\n-- start(noformat)\n-- Run the tests.\nSELECT results_eq(\n    'EXECUTE artists_long_songs(''Rock'', 10)',\n    $$VALUES\n        (22, 'Led Zeppelin'::varchar, '00:26:52.329'::interval),\n        (58, 'Deep Purple'::varchar, '00:19:56.094'::interval),\n        (59, 'Santana'::varchar, '00:17:50.027'::interval),\n        (136, 'Terry Bozzio, Tony Levin &amp; Steve Stevens'::varchar, '00:14:40.64'::interval),\n        (140, 'The Doors'::varchar, '00:11:41.831'::interval),\n        (90, 'Iron Maiden'::varchar, '00:11:18.008'::interval),\n        (23, 'Frank Zappa &amp; Captain Beefheart'::varchar, '00:11:17.694'::interval),\n        (128, 'Rush'::varchar, '00:11:07.428'::interval),\n        (76, 'Creedence Clearwater Revival'::varchar, '00:11:04.894'::interval),\n        (92, 'Jamiroquai'::varchar, '00:10:16.829'::interval)\n    $$,\n    'Verify return value'\n);\n-- Finish the tests and clean up.\n-- end(noformat)\n\nSELECT\n    *\nFROM\n    finish ();\nROLLBACK;\n</code></pre> <p>The test syntax is SQL only but with some additional functions installed by <code>pgTAP</code>. If you are not familiar with <code>pgTAP</code> you can go through it's documentation. But for this tutorial, it's sufficient to understand that the <code>{{ prepared_statement }}</code> Jinja variable is made available to this template, and when it's rendered it will expand to the actual query.</p> <p>Let's run the <code>render</code> command again.</p> <pre><code>tapestry render\n</code></pre> <p>And now you should see the pgTAP test file created at <code>output/tests/artists_long_songs-genre-limit_test.sql</code>.</p> <p>Note</p> <p>Here the file stem of the test template <code>path</code> itself was used as the output file name. But it's also possible to explicitly specify it in the manifest file (see output in <code>test_templates</code> docs).</p> <p>This is how the rendered test file looks like,</p> <pre><code>PREPARE artists_long_songs (varchar, int) AS\nSELECT\n    ar.artist_id,\n    ar.name,\n    max(milliseconds) * interval '1 ms' AS duration\nFROM\n    track t\n    INNER JOIN album al USING (album_id)\n    INNER JOIN artist ar USING (artist_id)\n    INNER JOIN genre g USING (genre_id)\nWHERE\n    g.name = $1\nGROUP BY\n    ar.artist_id\nORDER BY\n    -- Descending order because we want the top artists\n    duration DESC\nLIMIT $2;\n\nBEGIN;\nSELECT\n    plan (1);\n-- start(noformat)\n-- Run the tests.\nSELECT results_eq(\n    'EXECUTE artists_long_songs(''Rock'', 10)',\n    $$VALUES\n        (22, 'Led Zeppelin'::varchar, '00:26:52.329'::interval),\n        (58, 'Deep Purple'::varchar, '00:19:56.094'::interval),\n        (59, 'Santana'::varchar, '00:17:50.027'::interval),\n        (136, 'Terry Bozzio, Tony Levin &amp; Steve Stevens'::varchar, '00:14:40.64'::interval),\n        (140, 'The Doors'::varchar, '00:11:41.831'::interval),\n        (90, 'Iron Maiden'::varchar, '00:11:18.008'::interval),\n        (23, 'Frank Zappa &amp; Captain Beefheart'::varchar, '00:11:17.694'::interval),\n        (128, 'Rush'::varchar, '00:11:07.428'::interval),\n        (76, 'Creedence Clearwater Revival'::varchar, '00:11:04.894'::interval),\n        (92, 'Jamiroquai'::varchar, '00:10:16.829'::interval)\n    $$,\n    'Verify return value'\n);\n-- Finish the tests and clean up.\n-- end(noformat)\nSELECT\n    *\nFROM\n    finish ();\nROLLBACK;\n</code></pre>"},{"location":"user-guide/getting-started/#run-tests","title":"Run tests","text":"<p>Assuming that all the above mentioned prerequisites are installed, you can run the tests as follows,</p> <pre><code>sudo -u postgres pg_prove -d chinook --verbose output/tests/*.sql\n</code></pre> <p>If all goes well, the tests should pass and you should see output similar to,</p> <pre><code>1..1\nok 1 - Verify return value\nok\nAll tests successful.\nFiles=1, Tests=1,  0 wallclock secs ( 0.03 usr  0.01 sys +  0.01 cusr  0.00 csys =  0.05 CPU)\nResult: PASS\n</code></pre>"},{"location":"user-guide/getting-started/#thats-all","title":"That's all!","text":"<p>If you've reached this far, you should now have a basic understanding of what <code>tapestry</code> is and how to use it. Next, it'd be a good idea to learn about integrating tapestry with the CD/CI workflows of your project, to get an overall understanding of what all tools tapestry offers to help you make the most of SQL in project.</p> <p>Note</p> <p>The chinook example discussed in this tutorial can also be found in the github repo under the <code>examples/chinook</code> directory (there are a few more tests included for reference).</p>"},{"location":"user-guide/install/","title":"Installation","text":"<p>Currently, binaries for <code>x86_64</code> arch for Linux and MacOS can be downloaded from the Github release page. Binaries for <code>arm/aarch64</code> platform and Windows OS are not available yet.</p> <p>If you have the rust tool chain installed on your machine, you can build and install tapestry directly from github (without having to clone the repo)</p> <pre><code>cargo install --git https://github.com/naiquevin/tapestry.git\n</code></pre>"},{"location":"user-guide/install/#additional-dependencies","title":"Additional dependencies","text":"<p>Tapestry can be configured to depend on external SQL formatting tools for formatting the generated SQL files. In that case, it expects the respective tool to be installed on the system.</p> <p>Note that you need to install the formatting tools on the machine where you'd be rendering the SQL files using <code>tapestry</code> e.g. on your workstation and/or the build server.</p> <p>But these are not hard requirements as tapestry also ships with a basic inbuilt SQL formatter so that the generated files will be properly formatted without the need of any external dependencies.</p> <p>Refer to the SQL formatting section for more on this.</p>"},{"location":"user-guide/install/#dependencies-for-running-tests","title":"Dependencies for running tests","text":"<p>If you are using tapestry to render tests (which you should, because that's what the tool is meant for!) then you'd also need the <code>pgTAP</code> extension and the <code>pg_prove</code> command line tool.</p> <p><code>pgTAP</code> can be easily built from source. Refer to the instructions here.</p> <p>You can install <code>pg_prove</code> from a CPAN distribution as follows:</p> <pre><code>sudo cpan TAP::Parser::SourceHandler::pgTAP\n</code></pre> <p>Refer to the pgTAP installation guide for more details.</p> <p>As <code>tapestry</code> is a postgres specific tool, it goes without saying that you'd need a working installation of postgres to be able to run the tests. Please refer to the official documentation for that.</p>"},{"location":"user-guide/layouts/","title":"Layouts","text":"<p>Tapestry lets you control the layout of the query files i.e. how the generated SQL is organized in files. It supports two ways at present:</p> <ol> <li><code>one-file-one-query</code>: Each SQL query will be written to a separate file</li> <li><code>one-file-all-queries</code>: All SQL queries will be written to a single file</li> </ol> <p>To configure this, you need to specify the <code>query_output_layout</code> key in the manifest. The default option if not specified is <code>one-file-one-query</code>.</p>"},{"location":"user-guide/layouts/#layout-and-queriesoutput-field","title":"Layout and <code>queries[].output</code> field","text":"<p>Users may specify <code>output</code> field for every query, which is the path where the generated SQL output will be written. If <code>output</code> is not specified, it's value is derived from the query id. This works well for the <code>one-file-one-query</code> layout.</p> <p>Example:</p> <pre><code>[[queries]]\nid = \"artists_long_songs@genre*limit\"\ntemplate = \"artists_long_songs.sql.j2\"\nconds = [ \"genre\", \"limit\" ]\n</code></pre> <p>The derived value of output for the above will be <code>artists_long_songs-genre-limit.sql</code>.</p> <p>But when the layout is <code>one-file-all-queries</code>, it's expected that the <code>output</code> field of all queries must be the same. Otherwise the manifest fails to validate. To avoid duplication, a related setting <code>query_output_file</code> is provided.</p> <p>If layout = <code>one-file-all-queries</code>, it's recommended to set <code>query_output_file</code> and omit the <code>output</code> field for individual queries.</p> <p>Example:</p> <pre><code>query_output_layout = \"one-file-all-queries\"\nquery_output_file = \"queries.sql\"\n</code></pre> <p>Tip: If layout = <code>one-file-one-query</code>, then you must not set <code>query_output_file</code>. Whether or not to set the <code>output</code> field for individual queries is up to you.</p>"},{"location":"user-guide/layouts/#layout-and-query-tagging","title":"Layout and query tagging","text":"<p>Name tagging of queries is mandatory when layout is <code>one-file-all-queries</code>.</p> <p>Why? (If you are curious): Name tags make parsing individual queries from a single SQL file much more straightforward. The <code>status</code> command relies on parsing of individual queries from a single output file.</p>"},{"location":"user-guide/manifest/","title":"Manifest","text":"<p>Every <code>tapestry</code> \"project\" has a <code>tapestry.toml</code> file which is called the manifest. It is in TOML format and serves the dual purpose of configuration as well as a registry of the following entities:</p> <ol> <li><code>query_templates</code></li> <li><code>queries</code></li> <li><code>test_templates</code></li> </ol> <p>The various sections or top level <code>TOML</code> keys are described in detail below. When going through this doc, you may find it helpful to refer to the chinook example in the github repo. If you haven't checked the Getting started section, it's recommended to read it first.</p>"},{"location":"user-guide/manifest/#placeholder","title":"placeholder","text":"<p>The <code>placeholder</code> key is for configuring the style of the placeholder syntax for parameters i.e. the values values that are substituted into the statement when it is executed.</p> <p>Two options are supported:</p>"},{"location":"user-guide/manifest/#posargs","title":"posargs","text":"<p><code>posargs</code> is short for positional arguments. The placeholders refer to the parameters by positions e.g. <code>$1</code>, <code>$2</code> etc. This is the same syntax that's used for defining prepared statements or SQL functions in postgres.</p> <p>This option is suitable when your db driver or SQL library accepts queries in prepared statements syntax. E.g. sqlx (Rust).</p> <p>Default: The manifest file auto-generated upon running the <code>tapestry init</code> command will have,</p> <pre><code>placeholder = posargs\n</code></pre>"},{"location":"user-guide/manifest/#variables","title":"variables","text":"<p>When <code>placeholder=variables</code> placeholders are added in the rendered query using the variable substitution syntax of postgres. The variable name in the query is preceded with colon e.g. <code>:email</code>, <code>:department</code></p> <p>This option is suitable when your db driver or SQL library accepts queries with variables. E.g. yesql, hugsql (Clojure), aiosql (Python)</p> <p>Examples</p> Templateplaceholder = posargsplaceholder = variables <pre><code>SELECT\n    *\nFROM\n    employees\nWHERE\n    email = {{ placeholder('email') }}\n    AND department = {{ placeholder('department') }};\n</code></pre> <pre><code>SELECT\n    *\nFROM\n    employees\nWHERE\n    email = $1\n    AND department = $2;\n</code></pre> <pre><code>SELECT\n    *\nFROM\n    employees\nWHERE\n    email = :email\n    AND department = :department;\n</code></pre> <p>Note</p> <p>Note that the <code>prepared_statement</code> Jinja variable available in test templates will always have <code>posargs</code> based placeholders even if the <code>placeholder</code> config in manifest file is set to <code>variables</code>. That's the reason the Jinja var is named <code>prepared_statement</code>.</p>"},{"location":"user-guide/manifest/#query_templates_dir","title":"query_templates_dir","text":"<p>Path where the query templates are located. The path is always relative to the manifest file.</p> <p>Default: The manifest file auto-generated upon running the <code>tapestry init</code> command will have,</p> <pre><code>query_templates_dir = \"templates/queries\"\n</code></pre>"},{"location":"user-guide/manifest/#test_templates_dir","title":"test_templates_dir","text":"<p>Path where the query templates are located. The path is always relative to the manifest file.</p> <p>Default: The manifest file auto-generated upon running the <code>tapestry init</code> command will have,</p> <pre><code>test_templates_dir = \"templates/tests\"\n</code></pre>"},{"location":"user-guide/manifest/#queries_output_dir","title":"queries_output_dir","text":"<p>Path to the output dir for the rendered queries. This path also needs to be defined relative to the manifest file.</p> <p>Default: The manifest file auto-generated upon running the <code>tapestry init</code> command will have,</p> <pre><code>queries_output_dir = \"output/queries\"\n</code></pre> <p>A common use case to modify this config would be to store SQL files in a directory outside of the tapestry \"project\" dir, so that only the SQL files in that directory can be packaged into the build artifact. There's no need to include the query/test template and the <code>pgTAP</code> test files in the build artifact. E.g.</p> <pre><code>queries_output_dir = \"../sql_queries\"\n</code></pre>"},{"location":"user-guide/manifest/#tests_output_dir","title":"tests_output_dir","text":"<p>Path to the output dir for rendered <code>pgTAP</code> tests. The path is always relative to the manifest file.</p> <p>Default: The manifest file auto-generated upon running the <code>tapestry init</code> command will have,</p> <pre><code>tests_output_dir = \"output/tests\"\n</code></pre>"},{"location":"user-guide/manifest/#query_output_layout","title":"query_output_layout","text":"<p>Layout to be used for the generated query files. The two options are:</p> <ol> <li> <p><code>one-file-one-query</code>: Each SQL query will be written to a separate file</p> </li> <li> <p><code>one-file-all-queries</code>: All SQL queries will be written to a single file</p> </li> </ol> <p>It's optional. The default value is <code>one-file-one-query</code>.</p> <p>Example:</p> <pre><code>query_output_layout = \"one-file-all-queries\"\n</code></pre>"},{"location":"user-guide/manifest/#query_output_file","title":"query_output_file","text":"<p><code>query_output_file</code> is optional but it's use is valid only when the layout is <code>one-file-all-queries</code>. It basically saves the user from having to define the same <code>output</code> for all queries. Example:</p> <pre><code>query_output_layout = \"one-file-all-queries\"\nquery_output_file = \"queries.sql\"\n</code></pre> <p>Refer to the Layouts section of the user guide for more info on this topic.</p>"},{"location":"user-guide/manifest/#formatterpgformatter","title":"formatter.pgFormatter","text":"<p>This section is for configuring the <code>pg_format</code> tool that <code>tapestry</code> uses for formatting the rendered SQL files.</p> <p>There two config params under this section:</p>"},{"location":"user-guide/manifest/#exec_path","title":"exec_path","text":"<p>Location of the <code>pg_format</code> executable.</p>"},{"location":"user-guide/manifest/#conf_path","title":"conf_path","text":"<p>Path to the <code>pg_format</code> config file. It can be used for configuring the behavior of <code>pg_format</code> when it gets executed on rendered SQL. As with all paths that we've seen so far, this one is also relative to the manifest file.</p> <p>Example</p> <pre><code>[formatter.pgFormatter]\nexec_path = \"pg_format\"\nconf_path = \"./.pg_format/config\"\n</code></pre> <p>As mentioned in the installation guide, <code>pg_format</code> is not a mandatory requirement but it's recommended.</p> <p>Upon running the <code>tapestry init</code> command, this section will be included in the auto-generated manifest file only if the executable <code>pg_format</code> is found on <code>PATH</code>. In that case, a default <code>pg_format</code> config file will also be created.</p> <p>To read more about configuring <code>pg_format</code> in the context of <code>tapestry</code>, refer to the pg_format section of the docs.</p>"},{"location":"user-guide/manifest/#name_tagger","title":"name_tagger","text":"<p><code>name_tagger</code> is a TOML table, which if present in the manifest will cause the generated SQL queries to be name tagged.</p>"},{"location":"user-guide/manifest/#style","title":"style","text":"<p><code>name_tagger.style</code> can be used to control how name tags will be derived from query id. The two options are:</p> <ol> <li><code>kebab-case</code></li> <li><code>snake_case</code></li> <li><code>exact</code></li> </ol> <p>Any special characters in the query <code>id</code> will be replaced with an appropriate character based on the above option \u2014 hyphen in case of <code>kebab-case</code> and underscore in case of <code>snake_case</code>. The third option <code>exact</code> is different in the sense that the query <code>id</code> will be used as it is as the name tag.</p> <p>Example:</p> <pre><code>[name_tagger]\nstyle = \"kebab-case\"\n</code></pre> <p>Note</p> <p>Note the autological naming of options <code>kebab-case</code> (with a hyphen) v/s <code>snake_case</code> (with an underscore).</p>"},{"location":"user-guide/manifest/#query_templates","title":"query_templates","text":"<p><code>query_templates</code> is an array of tables in <code>TOML</code> parlance. So it needs to defined with double square brackets and can be specified multiple times in the manifest file.</p> <p>For every query template, there are two keys to be defined:</p>"},{"location":"user-guide/manifest/#path","title":"path","text":"<p>It's where the Jinja template file is located relative to the <code>query_templates_dir</code> defined earlier in the manifest. <code>path</code> itself is considered as the unique identifier for the query template.</p> <p>Use <code>.j2</code> extension as the convention for the query template file.</p>"},{"location":"user-guide/manifest/#all_conds","title":"all_conds","text":"<p>It's a set of values that will be converted to <code>cond__</code> Jinja variables that can be referenced inside the template. Note that they are defined in the manifest without the <code>cond__</code> suffix.</p> <p>This field is optional. If not specified, an empty set is considered as the default.</p> <p>For documentation on how to write a <code>query_template</code>, refer to Writing query templates</p> <p>Example: </p> <pre><code>[[query_templates]]\npath = \"artists_long_songs.sql.j2\"\nall_conds = [ \"genre\", \"limit\" ]\n\n[[query_templates]]\npath = \"songs_formats.sql.j2\"\nall_conds = [ \"artist\", \"file_format\", \"album_name\" ]\n</code></pre> <p>Note</p> <p>When <code>all_conds</code> is not specified, it essentially means that the query is a valid SQL statement and not a Jinja template. Then why define it as a template? The answer to that is \u2014 so that it can be embedded in tests.</p>"},{"location":"user-guide/manifest/#queries","title":"queries","text":"<p><code>queries</code> is an array of tables in <code>TOML</code> parlance. So it needs to defined with double square brackets and can be specified multiple times in the manifest file.</p> <p>A query can be defined using the following keys,</p>"},{"location":"user-guide/manifest/#id","title":"id","text":"<p><code>id</code> is an identifier for the query.</p>"},{"location":"user-guide/manifest/#template","title":"template","text":"<p><code>template</code> is a reference to a <code>query_template</code> defined previously in the manifest.</p>"},{"location":"user-guide/manifest/#conds","title":"conds","text":"<p><code>conds</code> is a subset of the <code>all_conds</code> key that's defined for the linked query template. It's an optional and if not specified, an empty set will be considered by default.</p>"},{"location":"user-guide/manifest/#output","title":"output","text":"<p><code>output</code> is the path to the output file where the SQL query will be rendered. It must be relative to the <code>queries_output_dir</code> config.</p> <p>It's optional to specify the <code>output</code>. If not specified, the filename of the output file will be derived by slugifying the <code>id</code>. This property allows us to use certain Naming conventions for giving suitable and consistent names to the queries.</p> <p>Example:</p> <pre><code>[[queries]]\nid = \"artists_long_songs@genre*limit\"\ntemplate = \"artists_long_songs.sql.j2\"\nconds = [ \"genre\", \"limit\" ]\n</code></pre> <p>The derived value of <code>output</code> for the above will be <code>artists_long_songs-genre-limit.sql</code>.</p>"},{"location":"user-guide/manifest/#name_tag","title":"name_tag","text":"<p><code>name_tag</code> can be optionally set to specify a custom name tag for the query. Name tags are prefixed to the SQL queries as comments and they are used by SQL loading libraries such as yesql, aiosql etc. Read more about in Name tagging queries.</p> <p>Note</p> <p>A query will be tagged with the specified <code>name_tag</code> only if <code>name_tagger</code> is set.</p>"},{"location":"user-guide/manifest/#test_templates","title":"test_templates","text":"<p><code>test_templates</code> is an array of tables in <code>TOML</code> parlance. So it needs to defined with double square brackets and can be specified multiple times in the manifest file.</p> <p>A <code>test_template</code> can be defined using the following keys,</p>"},{"location":"user-guide/manifest/#query","title":"query","text":"<p><code>query</code> is a reference to <code>query</code> defined in the manifest.</p>"},{"location":"user-guide/manifest/#path_1","title":"path","text":"<p><code>path</code> is the path to the jinja template for the <code>pgTAP</code> test. It must be relative to the <code>test_templates_dir</code>.</p> <p>Use <code>.j2</code> extension as the convention for the test template file.</p>"},{"location":"user-guide/manifest/#output_1","title":"output","text":"<p><code>output</code> is the path where the <code>pgTAP</code> test file will be rendered. It must be relative to the <code>tests_output_dir</code>. </p> <p>Specifying <code>output</code> for <code>test_templates</code> is optional. If not specified, it will be derived from the file stem of <code>path</code> i.e. by removing the <code>.j2</code> extension.</p> <p>For detailed documentation on how to write a <code>test_template</code>, refer to Writing test templates</p>"},{"location":"user-guide/naming-conventions/","title":"Query naming conventions","text":"<p>One of the problems that I have encountered when using SQL loading libraries such as yesql and aiosql is that the queries defined in SQL files need to be given unique names. Often, one ends up writing a group of queries that are mostly similar to each other and differ only slightly. Giving unique and consistent names to each query can become tricky.</p> <p>A tool like <code>tapestry</code> cannot automatically give a name to a query. However, since the queries are listed in the manifest file, we can partly address the problem with the use of naming conventions.</p> <p>These naming conventions involve clever use of special characters such as <code>@</code>, <code>+</code>, <code>&amp;</code> and <code>*</code>. Let's look at some examples from examples/chinook dir.</p> <pre><code>[[queries]]\nid = \"artists_long_songs@genre*limit\"\ntemplate = \"artists_long_songs.sql.j2\"\nconds = [ \"genre\", \"limit\" ]\n\n[[queries]]\nid = \"songs_formats@artist&amp;file_format+album\"\ntemplate = \"songs_formats.sql.j2\"\nconds = [ \"artist\", \"album_name\", \"file_format\" ]\n</code></pre> <p>In the above queries, the <code>id</code> is defined using an alphanumeric prefix (<code>artists_long_songs</code> and <code>songs_formats</code>) followed by suffix that's an encoding of the conditional Jinja variables relevant to the query.</p> <p>The convention is as follows,</p> <ul> <li><code>@</code> precedes \"cond\" vars used for conditionally including a filter   i.e. a <code>WHERE</code> clause.</li> </ul> <ul> <li><code>+</code> precedes \"cond\" vars used for conditionally returning a column</li> </ul> <ul> <li><code>*</code> precedes \"cond\" vars used for conditionally including any other   part of the query e.g. <code>LIMIT</code>, <code>ORDER BY</code> etc.</li> </ul> <ul> <li><code>&amp;</code> is used as a delimiter between two \"cond\" vars of same type   e.g. <code>@artist&amp;file_format</code>.</li> </ul> <p>The name of the <code>output</code> file for the SQL query will be generated by slugifying the id i.e. by replacing the above special characters with hyphen (<code>-</code>). In case of the above two queries, the output file names will be <code>artists_long_songs-genre-limit.sql</code> and <code>songs_formats-artist-file_format-album.sql</code> respectively.</p> <p>Note that these naming conventions are only recommended by <code>tapestry</code> and are not mandatory.</p>"},{"location":"user-guide/pg-format/","title":"Configuring pg_format","text":"<p><code>tapestry</code> can be configured to use <code>pg_format</code> for formatting the rendered SQL files. This makes sure that,</p> <ul> <li>the rendered SQL files have consistent indentation</li> <li>you don't need to worry about SQL indentation when writing Jinja   templates</li> </ul> <p>It can be installed on MacOS as follows,</p> <pre><code>brew install pgformatter\n</code></pre> <p>During project initialization, if tapestry finds <code>pg_format</code> installed on your system (and in <code>$PATH</code>), it will show it as one of the formatter options. If you choose it, then following lines will be added to the <code>tapestry.toml</code> manifest file.</p> <pre><code>[formatter.pgFormatter]\n## (required) Location of the pg_format executable\nexec_path = \"pg_format\"\n## (optional) path to the pg_format conf file.\nconf_path = \"./.pg_format/config\"\n</code></pre> <p>The behavior of <code>pg_format</code> tool in the context of <code>tapestry</code> can be configured by adding a config file. The sample config file in the <code>pg_format</code> github repo can be used for reference.</p> <p>The <code>tapestry init</code> command also generates a default config file, located at <code>.pg_format/config</code> (relative to the manifest file) and looks like this,</p> <pre><code># Lines between markers 'start(noformat)' and 'end(noformat)' will not\n# be formatted. If you want to customize the markers, you may do so by\n# modifying this parameter.\nplaceholder=start\\(noformat\\).+end\\(noformat\\)\n\n# Add a list of function to be formatted as PG internal\n# functions. Paths relative to the 'tapestry.toml' file will also work\n#extra-function=./.pg_format/functions.lst\n\n# Add a list of keywords to be formatted as PG internal keywords.\n# Paths relative to the 'tapestry.toml' file will also work\n#extra-keyword=./.pg_format/keywords.lst\n\n# -- DANGER ZONE --\n#\n# Please donot change the following config parameters. Tapestry may\n# not work otherwise.\nmultiline=1\nformat=text\noutput=\n</code></pre> <p>As you can see, the generated file itself is well documented.</p>"},{"location":"user-guide/pg-format/#disallowed-configuration","title":"Disallowed configuration","text":"<p>In the context of <code>tapestry</code>, some <code>pg_format</code> config params are disallowed (or they need to configured only in a certain way) for proper functioning of <code>tapestry</code>. These are explicitly defined with the intended value in the config file and annotated with <code>DANGER ZONE</code> warning in the comments. These must not be changed.</p>"},{"location":"user-guide/pg-format/#selectively-opting-out-of-sql-formatting","title":"Selectively opting out of SQL formatting","text":"<p>A commonly faced problem with formatting <code>pgTAP</code> tests using <code>pg_format</code> is that hard coded expected values get formatted in a way that could make the test case unreadable for humans.</p> <p>Example: Consider the following <code>pgTAP</code> test case written in a test template file,</p> <pre><code>SELECT results_eq(\n    'EXECUTE artists_long_songs(''Rock'', 2)',\n    $$VALUES\n        (22, 'Led Zeppelin'::varchar, '00:26:52.329'::interval),\n        (58, 'Deep Purple'::varchar, '00:19:56.094'::interval)\n    $$,\n    'Verify return value'\n);\n</code></pre> <p>By default <code>pg_format</code> would format the above SQL snippet as follows,</p> <pre><code>SELECT\n    results_eq ('EXECUTE artists_long_songs(''Rock'', 2)', $$\n    VALUES (22, 'Led Zeppelin'::varchar, '00:26:52.329'::interval), (58, 'Deep Purple'::varchar, '00:19:56.094'::interval) $$, 'Verify return value');\n</code></pre> <p>To retain the readability, we need to preserve the user's custom indentation. This is where the <code>placeholder</code> config param of <code>pg_format</code> is useful</p> <p>Note</p> <p>pg_format's <code>placeholder</code> config is not to be confused with <code>placeholder</code> config key in tapestry's manifest.</p> <p>This can be done by adding <code>noformat</code> markers before and after the snippet.</p> <pre><code>-- start(noformat)\nSELECT results_eq(\n    'EXECUTE artists_long_songs(''Rock'', 2)',\n    $$VALUES\n        (22, 'Led Zeppelin'::varchar, '00:26:52.329'::interval),\n        (58, 'Deep Purple'::varchar, '00:19:56.094'::interval)\n    $$,\n    'Verify return value'\n);\n-- end(noformat)\n</code></pre> <p>If you want to customize the markers for whatever reason, you can modify the <code>placeholder</code> param in the <code>pg_format</code> config file.</p>"},{"location":"user-guide/query-tags/","title":"Query tags","text":""},{"location":"user-guide/query-tags/#name-tagging-queries","title":"Name tagging queries","text":"<p>Typically, the output query files rendered by tapestry are intended to be used by libraries such as <code>yesql</code>, <code>aiosql</code> etc. These libraries require the queries to be \"name-tagged\". Tagging is done by simply adding a comment before the query as follows,</p> <pre><code>-- name: my-query\n-- A simple query\nSELECT 1;\n</code></pre> <p>This way, these libraries can map the queries with the functions that it generates in code. These functions wraps around the database client/driver code and provides an easy interface for the user.</p> <p>Name-tagging queries is specially makes sense when all queries are rendered in the same output file (See <code>one-file-all-queries</code> in layouts).</p> <p>The following example is taken from yesql's README:</p> <pre><code>-- name: users-by-country\nSELECT *\nFROM users\nWHERE country_code = :country_code\n</code></pre> <p>...and then read that file to turn it into a regular Clojure function:</p> <pre><code>(defqueries \"some/where/users_by_country.sql\"\n   {:connection db-spec})\n\n;;; A function with the name `users-by-country` has been created.\n;;; Let's use it:\n(users-by-country {:country_code \"GB\"})\n;=&gt; ({:name \"Kris\" :country_code \"GB\" ...} ...)\n</code></pre>"},{"location":"user-guide/query-tags/#name-tag-format","title":"Name tag format","text":"<p>The name tag is just a comment with a prefix <code>name:</code>. But if any other comment lines are present before a query, then the name tag should precede it.</p> <pre><code>&lt;name tag&gt;\n&lt;additional docstring if any&gt;\n&lt;query&gt;\n</code></pre> <p>Correct \u2611</p> <pre><code>-- name: my-query\n-- A simple query\nSELECT 1;\n</code></pre> <p>Incorrect \u2612</p> <pre><code>-- A simple query\n-- name: my-query\nSELECT 1;\n</code></pre>"},{"location":"user-guide/query-tags/#deriving-name-tags-from-id","title":"Deriving name tags from id","text":"<p>The name tagging config in the manifest file will look like this:</p> <pre><code>[name_tagger]\nstyle = \"kebab-case\"\n</code></pre> <p>This will result in name tags to be added to query output files. By default, the name tags are derived from the query ids. The <code>style</code> setting allows us to control how the id should be slugified to derive the name tag. For e.g. <code>kebab-case</code> will cause all non-alphanumeric characters in the id to be replaced by hyphens.</p> <p>The other options for style are <code>snake_case</code> and <code>exact</code>.</p>"},{"location":"user-guide/query-tags/#custom-name-tags","title":"Custom name tags","text":"<p>The above method derives name tags from query ids. But yesql and aiosql sometimes require the query names to be suffixed with specific characters to indicate specific operations. Example: In yesql, the name tags for INSERT/UPDATE/DELETE statements need to be suffixed with <code>!</code>.</p> <pre><code>-- name: save-person!\nUPDATE person\n    SET name = :name\n    WHERE id = :id\n</code></pre> <p>There are two ways to achieve this:</p> <ol> <li> <p>Specify <code>exact</code> as the <code>name_tagger.style</code>. Then the query    <code>id</code> itself to be used as the name tag (as it    is).</p> </li> <li> <p>Specify the optional <code>queries[].name_tag</code>    field when defining the queries.</p> </li> </ol> <p>While it may seem like the first approach involves less effort, the downside is that we'd be giving up on the Naming conventions that tapestry recommends.</p> <p>Libraries such as yesql and aiosql usually don't allow special characters in the name tags as they use them to generate functions in code. So yesql recommends the name tags to be in <code>kebab-case</code> as Clojure functions follow that convention, whereas aiosql needs the name tags to be in <code>snake_case</code> as that's the requirement and also the convention in Python.</p>"},{"location":"user-guide/query-tags/#disabling-name-tagging","title":"Disabling name tagging","text":"<p>Name tagging can be disabled by simply removing the <code>[name_tagger]</code> TOML table from the manifest file.</p> <p>Note however that name tagging cannot be disabled if the layout is <code>one-file-all-queries</code>. Most tapestry commands will fail with validation error in that case.</p>"},{"location":"user-guide/query-templates/","title":"Writing query templates","text":"<p>Query templates are Jinja template files. One query template can be used for generating multiple SQL queries. </p> <p>Often, an application needs to issue mostly similiar (or slightly different) queries to the db based on user input. Some examples: </p> <ul> <li>two queries that are exactly similar, except that one returns all   columns i.e. <code>*</code> whereas the other returns only selected rows</li> </ul> <ul> <li>two queries that are exactly the same, except that one has a limit</li> </ul> <ul> <li>multiple similar queries but different combination of <code>WHERE</code>   clauses</li> </ul> <p>Using Jinja templates, it's possible to write a single query template that can render multiple SQL queries. This is possible with a combination of Jinja variables and <code>{% if .. %}...{% endif %}</code> blocks. This is pretty much the main idea behind query templates.</p>"},{"location":"user-guide/query-templates/#cond-variables","title":"\"cond\" variables","text":"<p>Query templates need to be defined in the manifest where we specify <code>all_conds</code> which is a set of \"cond\" vars that the template supports.</p> <p>Let's look at a query template from the chinook example distributed with the github repo.</p> <pre><code>SELECT\n    track.name as title,\n    artist.name as artist_name,\n    {% if cond__album_name %}\n      album.title as album_name,\n    {% endif %}\n    media_type.name as file_format\nFROM\n    album\n    JOIN artist USING (artist_id)\n    LEFT JOIN track USING (album_id)\n    JOIN media_type USING (media_type_id)\n\n{% if cond__artist or cond__file_format %}\n  WHERE\n  {% set num_conds = 0 %}\n  {% if cond__artist %}\n    artist.name = {{ placeholder('artist') }}\n    {% set num_conds = num_conds + 1 %}\n  {% endif %}\n\n  {% if cond__file_format %}\n    {% if num_conds &gt; 0 %}\n      AND\n    {% endif %}\n    media_type.name = {{ placeholder('file_format') }}\n    {% set num_conds = num_conds + 1 %}\n  {% endif %}\n{% endif %}\n;\n</code></pre> <p>The entry in the manifest file for the above <code>query_template</code> is,</p> <pre><code>[[query_templates]]\npath = \"songs_formats.sql.j2\"\nall_conds = [ \"artist\", \"file_format\", \"album_name\" ]\n</code></pre> <p>Because of the 3 <code>all_conds</code> defined in the manifest file, we have the following Jinja variables available inside the Jinja template.</p> <ol> <li><code>cond__artist</code></li> <li><code>cond__file_format</code></li> <li><code>cond__album_name</code></li> </ol> <p>The <code>cond__artist</code> and <code>cond__file_format</code> vars are used for conditionally including <code>WHERE</code> clauses. Because we want to add the <code>WHERE</code> clause only if either of the two vars are true, and because we want to add the <code>AND</code> operator only if both are true, nested <code>if</code> blocks are used and a temp \"counter\" variable <code>num_conds</code> is defined i.e. it's assigned to <code>0</code> and then incremented by 1 if the <code>cond__artist</code> var is true.</p> <p>The third variable <code>cond__album_name</code> is used for conditionally including a column in the returned result.</p>"},{"location":"user-guide/query-templates/#query","title":"Query","text":"<p>Now let's look at how a <code>query</code> associated with this template is defined in the manifest.</p> <pre><code>[[queries]]\nid = \"songs_formats@artist+album\"\ntemplate = \"songs_formats.sql.j2\"\nconds = [ \"artist\", \"album_name\" ]\noutput = \"songs_formats__artist__album.sql\"\n</code></pre> <p>In this query, only 2 of the 3 \"cond\" variables will be true.</p> <p>As a total of 3 <code>all_conds</code> values are supported by the query template, 8 different queries can be generated from it using different subsets of <code>all_conds</code>.</p> <pre><code>[ ]\n[ \"artists\" ]\n[ \"artists\", \"file_format\" ]\n[ \"artists\", \"album_name\" ]\n[ \"file_format\" ]\n[ \"file_format\", \"album_name\" ]\n[ \"album_name\" ]\n[ \"artist\", \"file_format\", \"album_name\" ]\n</code></pre>"},{"location":"user-guide/sql-formatter/","title":"Configuring sql-formatter","text":"<p>sql-formatter is a Javascript library and command line tool for pretty printing SQL. It supports multiple SQL dialects including postgresql, and hence makes for a pretty good external tool that tapestry can use for formatting the generated SQL.</p> <p>You can easily install it using npm,</p> <pre><code>npm install -g sql-formatter\n</code></pre> <p>During project initialization, if <code>sql-formatter</code> is found installed on your system (and in <code>$PATH</code>), it will be shown as one of the formatter options. Upon choosing it, following lines will be added to the <code>tapestry.toml</code> manifest file.</p> <pre><code>[formatter.sql-formatter]\n# (required) Location of the sql-formatter executable\nexec_path = \"sql-formatter\"\n# (optional) path to the json conf file.\nconf_path = \"./.sql-formatter/config.json\"\n</code></pre> <p><code>sql-formatter</code> can be configured through a JSON file. The <code>init</code> command also dumps a default JSON file at <code>./.sql-formatter/config.json</code>, relative to the manifest file, with the following contents:</p> <pre><code>{\n  \"language\": \"postgresql\",\n  \"tabWidth\": 4,\n  \"keywordCase\": \"upper\",\n  \"linesBetweenQueries\": 2\n}\n</code></pre> <p>Refer to the sql-formatter documentation for more configuration options.</p>"},{"location":"user-guide/sqlfluff/","title":"Configuring sqlfluff","text":"<p>sqlfluff is a feature rich SQL formatter that's written in Python and hence is an external dependency for tapestry.</p> <p><code>sqlfluff</code> recognizes a file named <code>./.sqlfluff</code> a standard configuration file to load config from. Tapestry capitalizes on this so that there's no need to invent a new config format.</p> <p>The configuration options for <code>sqlfluff</code> are quite extensive and well documented - https://docs.sqlfluff.com/en/stable/configuration/index.html.</p> <p>During project initialization, if <code>sqlfluff</code> is found installed on your system (and in <code>$PATH</code>), it will be shown as one of the formatter options. Upon choosing it, following lines will be added to the <code>tapestry.toml</code> manifest file.</p> <pre><code>[formatter.sqlfluff]\n# (required) Location of the sqlfluff executable\nexec_path = \"sqlfluff\"\n</code></pre> <p>Additionally, it will also create the <code>.sqlfluff</code> config file alongside the manifest file.</p> <pre><code>[sqlfluff]\ndialect = postgres\n</code></pre> <p>You may refer to sqlfluff documentation to configure formatting as per your preferences.</p> <p>Note</p> <p>Unlike in pgFormatter's config, the path to the sqlfluff config file doesn't need to be explicitly specified in the manifest file. Similar to normal functioning of <code>sqlfluff</code>, config will be implicitly loaded from a file named <code>./.sqlfluff</code> in the current directory. Since tapestry commands are run from the same dir that this file is created in, it just works.</p>"},{"location":"user-guide/sqlformat-rs/","title":"Configuring sqlformat","text":"<p><code>sqlformat</code> is the inbuilt formatter supported by tapestry. It's implemented using the the sqlformat crate.</p> <p>It provides 3 basic config options:</p> <ol> <li> <p><code>indentation</code>: Default is 4 spaces</p> </li> <li> <p><code>uppercase</code>: Whether or not reserved keywords should be converted to    UPPERCASE.</p> </li> <li> <p><code>lines_between_queries</code>: No. of empty lines between two queries.</p> </li> </ol> <p>During project initialization, <code>sqlformat</code> is shown as one of the options, besides other external formatters. Upon choosing it as the preferred formatter, following lines are added to the <code>tapestry.toml</code> manifest file.</p> <pre><code>[formatter.sqlformat-rs]\n# (optional) No. of spaces to indent by\nindent = 4\n# (optional) Use ALL CAPS for reserved keywords\nuppercase = true\n# (optional) No. of line breaks after a query\nlines_between_queries = 1\n</code></pre>"},{"location":"user-guide/test-templates/","title":"Test templates","text":"<p>Just like <code>query_templates</code>, <code>test_templates</code> are also Jinja template files. But while one query template could be used to generate several queries, one test template can be used to generate only one <code>pgTAP</code> test file.</p> <p>However, many test templates can be associated with a single query. In other words, if multiple <code>pgTAP</code> test suites are to be written for the same query, that's possible.</p> <p>The test syntax is SQL only but with some additional functions installed by <code>pgTAP</code>. If you are not familiar with <code>pgTAP</code> you can go through it's documentation. Important thing to note is that the Jinja variable <code>{{ prepared_statement }}</code> is made available to every test template, and at the time of rendering, it will expand to the actual query.</p> <p>Let's look at a templates from the chinook example.</p> <p>Refer to the test template <code>songs_formats-afa_test.sql.j2</code>. The first few lines are:</p> <pre><code>PREPARE song_formats (varchar, varchar) AS\n{{ prepared_statement }};\n</code></pre> <p>Here we're using the <code>prepared_statement</code> Jinja variable to create a prepared statement for the user session. The name of the prepared statement is <code>song_formats</code> and it takes two positional args, both of type <code>varchar</code>.</p> <p>Later in the same file, the prepared statement is executed as part of a <code>pgTAP</code> test case,</p> <pre><code>SELECT results_eq(\n    'EXECUTE song_formats(''Iron Maiden'', ''Protected AAC audio file'')',\n    $$VALUES\n      ...\n      ...\n    $$,\n    'Verify return value'\n);\n</code></pre> <p>Check the <code>songs_formats-afa_test.sql</code> output file to see how the actual test file looks like.</p> <p>Note</p> <p>Note that the SQL query that <code>prepared_statement</code> Jinja var expands to will always have <code>posargs</code> based placeholders, even if the <code>placeholder</code> config in manifest file is set to <code>variables</code>. That's the reason why the Jinja var is named <code>prepared_statement</code></p>"},{"location":"user-guide/test-templates/#function-instead-of-ps","title":"Function instead of PS","text":"<p>Sometimes it's tedious to test for result sets returned by the query. In such cases, it helps to manipulate the result returned by the query and compare a derived property. E.g. If a query results too many rows, it's easier to compare the count than the actual values in the rows.</p> <p>One limitation of prepared statements and the <code>EXECUTE</code> syntax for executing them is that it's not sub-query friendly i.e. it's not possible to execute a prepared statement as part of another query.</p> <p>The following is NOT valid SQL</p> <pre><code>SELECT\n    count(*)\nFROM (EXECUTE song_formats ('Iron Maiden', 'Protected AAC audio file'));\n</code></pre> <p>In such cases, we can define a SQL function using the same <code>prepared_statement</code> Jinja variable.</p> <p>An example of this can be found in the chinook example - <code>all_artists_long_songs_test.sql.j2</code></p> <pre><code>CREATE OR REPLACE FUNCTION all_artists_long_songs ()\nRETURNS SETOF record\nAS $$\n{{ prepared_statement }}\n$$ LANGUAGE sql;\n\nBEGIN;\nSELECT\n    plan (1);\n\n-- start(noformat)\n-- Run the tests.\nSELECT is(count(*), 204::bigint) from all_artists_long_songs() AS (artist_id int, name text, duration interval);\n-- Finish the tests and clean up.\n-- end(noformat)\n\nSELECT\n    *\nFROM\n    finish ();\nROLLBACK;\n</code></pre>"},{"location":"user-guide/test-templates/#test-fixtures","title":"Test fixtures","text":"<p>When it comes to automated tests, It's a very common requirement to setup some test data to be able to write test cases. <code>pgTAP</code> tests are not any different. In case of <code>pgTAP</code> one needs to create test data in the database.</p> <p>Since <code>pgTAP</code> tests are just SQL files, test data creation can be done using SQL itself in the same file. Reusable setup code can also be extracted into SQL functions that can be created as part of importing the database schema.</p> <p>The chinook directory doesn't include an example of this. But here's an example from one of my real projects that uses <code>tapestry</code>.</p> <p>In my project, there are two entities <code>categories</code> and <code>items</code> (having tables of the same names) with <code>one-to-many</code> relationship i.e. one category can have multiple items.</p> <p>In several <code>pgTAP</code> tests, a few categories and items need to be created. To do this, a function is defined as follows,</p> <pre><code>CREATE OR REPLACE FUNCTION tapestry.setup_category_n_items (cat_id varchar, item_idx_start integer, item_idx_end integer)\n    RETURNS void\n    AS $$\n    INSERT INTO categories (id, name)\n        VALUES (cat_id, initcap(replace(cat_id, '-', ' ')));\n    INSERT INTO items (id, name, category_id)\n    SELECT\n        'item-' || t AS id,\n        'Item ' || t AS name,\n        cat_id AS category_id\n    FROM\n        generate_series(item_idx_start, item_idx_end) t;\n$$\nLANGUAGE sql;\n</code></pre> <p>And then it's used in <code>pgTAP</code> tests like this, </p> <pre><code>...\n\nBEGIN;\nSELECT plan(1);\n\n-- Fixtures\n-- create 2 categories, 'cat-a' and 'cat-b' each having 5 items\nSELECT\n    tapestry.setup_category_n_items ('cat-a', 1, 5);\nSELECT\n    tapestry.setup_category_n_items ('cat-b', 6, 10);\n\n-- Test cases\n\n...\n</code></pre>"}]}